{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# U-Net customizada linha plantio IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T15:31:43.197789Z",
     "start_time": "2022-09-15T15:31:40.777808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T15:31:44.551141Z",
     "start_time": "2022-09-15T15:31:43.206303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T15:31:44.865353Z",
     "start_time": "2022-09-15T15:31:44.553644Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!jupyter nbextension enable varInspector/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Enable\n",
    "    L1\n",
    "        Collapsible Headings\n",
    "        Highlight selected word\n",
    "    L2\n",
    "        ExecuteTime\n",
    "        Table of Contents\n",
    "        Variable Inspector\n",
    "    L3\n",
    "        contrib_nbextensions_help_item\n",
    "        Hinterland\n",
    "        Nbextensions dashboard tab\n",
    "        Snippets Menu\n",
    "    L4\n",
    "        Nbextensions edit menu item\n",
    "        spellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T23:49:14.422275Z",
     "start_time": "2023-07-16T23:49:08.337483Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# save predit img_pr\n",
    "import glob\n",
    "\n",
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T01:54:28.543587Z",
     "start_time": "2023-07-16T01:54:28.505830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available\", len(physical_devices))\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# U-Net functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:05:13.838965Z",
     "start_time": "2023-01-15T23:05:13.819000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "# https://github.com/karolzak/keras-unet/blob/master/notebooks/kz-whale-tails.ipynb\n",
    "\n",
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:05:15.880660Z",
     "start_time": "2023-01-15T23:05:15.857728Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ModelSaver:\n",
    "    def __init__(self, history, base_output_path):\n",
    "        self.history = history\n",
    "        self.base_output_path = base_output_path\n",
    "        try:\n",
    "            #os.mkdir(base_output_path)\n",
    "            os.makedirs(base_output_path)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "\n",
    "    def saveModel(self, model):\n",
    "        fileName = os.path.join(self.base_output_path,\"result.h5\")\n",
    "        model.save(fileName)\n",
    "        print(\"saved to:\", fileName)\n",
    "\n",
    "    def plotAndSaveMetrics(self, metric_name, show_val):\n",
    "        #plt.clf() # Clear Figure 2 with clf() function:\n",
    "\n",
    "        plt.plot(self.history.history[str(metric_name)])\n",
    "        if show_val:\n",
    "            plt.plot(self.history.history['val_'+str(metric_name)])\n",
    "        plt.title(\"Acurácia por épocas\")\n",
    "        plt.xlabel(\"épocas\")\n",
    "        plt.legend(['treino','validação'])\n",
    "        output_path = os.path.join(self.base_output_path,\"acc_por_epocas\")\n",
    "        plt.savefig(output_path)\n",
    "        print(\"saved to:\", output_path)\n",
    "        plt.show() # end figure and plot\n",
    "\n",
    "    def plotAndSaveLoss(self, show_val):\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        if show_val:\n",
    "            plt.plot(self.history.history['val_loss'])\n",
    "        plt.title(\"Perda por épocas\")\n",
    "        plt.xlabel(\"épocas\")\n",
    "        plt.legend(['treino','validação'])\n",
    "        output_path = os.path.join(self.base_output_path,\"loss_por_epocas\")\n",
    "        print(\"saved to:\", output_path)\n",
    "        plt.savefig(output_path)\n",
    "        plt.show() # end figure and plot\n",
    "\n",
    "    def predictAndSave(self, model, imgs, nomes_imgs, images_to_show):\n",
    "        predict_imgs = model.predict(imgs)\n",
    "\n",
    "        #plot_imgs(org_imgs=imgs, mask_imgs=predict_imgs, nm_img_to_plot=10, figsize=6) #<---------\n",
    "\n",
    "        base_output_result_img = os.path.join(self.base_output_path,\"result_images\")\n",
    "        if(os.path.isdir(base_output_result_img) == False):\n",
    "            try:\n",
    "                os.mkdir(base_output_result_img)\n",
    "            except OSError as error:\n",
    "                print(error)\n",
    "\n",
    "        print(\"writing img:\")\n",
    "        for i in range(len(nomes_imgs)):\n",
    "            #file_name = nomes_imgs[i].replace(\".jpg\", \".png\") #<-----------------\n",
    "            #file_name = file_name.replace(\".jpg\", \".png\")\n",
    "\n",
    "            file_name = nomes_imgs[i]\n",
    "\n",
    "            output_path = os.path.join(base_output_result_img , file_name)\n",
    "            #print(\"writing img:\",i,\" to\", output_path)\n",
    "            print(i, end = \" \")\n",
    "            cv2.imwrite(output_path, predict_imgs[i] * 255.0)\n",
    "\n",
    "    def saveHistory(self):\n",
    "        output_path = os.path.join(self.base_output_path,\"history.csv\")\n",
    "        # convert the history.history dict to a pandas DataFrame:\n",
    "        hist_df = pd.DataFrame(history.history)\n",
    "        # or save to csv:\n",
    "        #hist_csv_file = 'history.csv'\n",
    "        with open(output_path, mode='w') as f:\n",
    "            hist_df.to_csv(f)\n",
    "\n",
    "        print(\"saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T23:49:14.445245Z",
     "start_time": "2023-07-16T23:49:14.432917Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/karolzak/keras-unet/blob/9b7aff5247fff75dc4e2a11ba9c45929b9166d1f/keras_unet/utils.py\n",
    "\n",
    "MASK_COLORS = [\"red\", \"green\", \"blue\", \"yellow\", \"magenta\", \"cyan\"]\n",
    "\n",
    "def mask_to_rgba(mask, color=\"red\"):\n",
    "    \"\"\"\n",
    "    Converts binary segmentation mask from white to red color.\n",
    "    Also adds alpha channel to make black background transparent.\n",
    "\n",
    "    Args:\n",
    "        mask (numpy.ndarray): [description]\n",
    "        color (str, optional): Check `MASK_COLORS` for available colors. Defaults to \"red\".\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [description]\n",
    "    \"\"\"\n",
    "    assert(color in MASK_COLORS)\n",
    "    assert(mask.ndim==3 or mask.ndim==2)\n",
    "\n",
    "    h = mask.shape[0]\n",
    "    w = mask.shape[1]\n",
    "    zeros = np.zeros((h, w))\n",
    "    ones = mask.reshape(h, w)\n",
    "    if color == \"red\":\n",
    "        return np.stack((ones, zeros, zeros, ones), axis=-1)\n",
    "    elif color == \"green\":\n",
    "        return np.stack((zeros, ones, zeros, ones), axis=-1)\n",
    "    elif color == \"blue\":\n",
    "        return np.stack((zeros, zeros, ones, ones), axis=-1)\n",
    "    elif color == \"yellow\":\n",
    "        return np.stack((ones, ones, zeros, ones), axis=-1)\n",
    "    elif color == \"magenta\":\n",
    "        return np.stack((ones, zeros, ones, ones), axis=-1)\n",
    "    elif color == \"cyan\":\n",
    "        return np.stack((zeros, ones, ones, ones), axis=-1)\n",
    "\n",
    "def get_cmap(arr):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): [description]\n",
    "\n",
    "    Returns:\n",
    "        string: [description]\n",
    "    \"\"\"\n",
    "    if arr.ndim == 3:\n",
    "        return \"gray\"\n",
    "    elif arr.ndim == 4:\n",
    "        if arr.shape[3] == 3:\n",
    "            return \"jet\"\n",
    "        elif arr.shape[3] == 1:\n",
    "            return \"gray\"\n",
    "\n",
    "def zero_pad_mask(mask, desired_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        mask (numpy.ndarray): [description]\n",
    "        desired_size ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [description]\n",
    "    \"\"\"\n",
    "    pad = (desired_size - mask.shape[0]) // 2\n",
    "    padded_mask = np.pad(mask, pad, mode=\"constant\")\n",
    "\n",
    "    return padded_mask\n",
    "\n",
    "def reshape_arr(arr):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): [description]\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [description]\n",
    "    \"\"\"\n",
    "    if arr.ndim == 3:\n",
    "        return arr\n",
    "    elif arr.ndim == 4:\n",
    "        if arr.shape[3] == 3:\n",
    "            return arr\n",
    "        elif arr.shape[3] == 1:\n",
    "            return arr.reshape(arr.shape[0], arr.shape[1], arr.shape[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Old ploplot_imgst and loadImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_imgs(org_imgs, mask_imgs, pred_imgs=None, nm_img_to_plot=10,\n",
    "              figsize=4, alpha=0.5, color=\"red\"):\n",
    "    \"\"\"\n",
    "    Image plotting for semantic segmentation data.\n",
    "    Last column is always an overlay of ground truth or prediction\n",
    "    depending on what was provided as arguments.\n",
    "    Args:\n",
    "        org_imgs (numpy.ndarray): Array of arrays representing a collection of original images.\n",
    "        mask_imgs (numpy.ndarray): Array of arrays representing a collection of mask images (grayscale).\n",
    "        pred_imgs (numpy.ndarray, optional): Array of arrays representing a collection of prediction masks images.. Defaults to None.\n",
    "        nm_img_to_plot (int, optional): How many images to display. Takes first N images. Defaults to 10.\n",
    "        figsize (int, optional): Matplotlib figsize. Defaults to 4.\n",
    "        alpha (float, optional): Transparency for mask overlay on original image. Defaults to 0.5.\n",
    "        color (str, optional): Color for mask overlay. Defaults to \"red\".\n",
    "    \"\"\" # NOQA E501\n",
    "    assert(color in MASK_COLORS)\n",
    "\n",
    "    if nm_img_to_plot > org_imgs.shape[0]:\n",
    "        nm_img_to_plot = org_imgs.shape[0]\n",
    "    im_id = 0\n",
    "    org_imgs_size = org_imgs.shape[1]\n",
    "\n",
    "    org_imgs = reshape_arr(org_imgs)\n",
    "    mask_imgs = reshape_arr(mask_imgs)\n",
    "    if not (pred_imgs is None):\n",
    "        cols = 4\n",
    "        pred_imgs = reshape_arr(pred_imgs)\n",
    "    else:\n",
    "        cols = 3\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nm_img_to_plot, cols, figsize=(cols * figsize, nm_img_to_plot * figsize), squeeze=False\n",
    "    )\n",
    "    axes[0, 0].set_title(\"original\", fontsize=15)\n",
    "    axes[0, 1].set_title(\"ground truth\", fontsize=15)\n",
    "    if not (pred_imgs is None):\n",
    "        axes[0, 2].set_title(\"prediction\", fontsize=15)\n",
    "        axes[0, 3].set_title(\"overlay\", fontsize=15)\n",
    "    else:\n",
    "        axes[0, 2].set_title(\"overlay\", fontsize=15)\n",
    "    for m in range(0, nm_img_to_plot):\n",
    "        axes[m, 0].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "        axes[m, 0].set_axis_off()\n",
    "        axes[m, 1].imshow(mask_imgs[im_id], cmap=get_cmap(mask_imgs))\n",
    "        axes[m, 1].set_axis_off()\n",
    "        if not (pred_imgs is None):\n",
    "            axes[m, 2].imshow(pred_imgs[im_id], cmap=get_cmap(pred_imgs))\n",
    "            axes[m, 2].set_axis_off()\n",
    "            axes[m, 3].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "            axes[m, 3].imshow(\n",
    "                mask_to_rgba(\n",
    "                    zero_pad_mask(pred_imgs[im_id], desired_size=org_imgs_size),\n",
    "                    color=color,\n",
    "                ),\n",
    "                cmap=get_cmap(pred_imgs),\n",
    "                alpha=alpha,\n",
    "            )\n",
    "            axes[m, 3].set_axis_off()\n",
    "        else:\n",
    "            axes[m, 2].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "            axes[m, 2].imshow(\n",
    "                mask_to_rgba(\n",
    "                    zero_pad_mask(mask_imgs[im_id], desired_size=org_imgs_size),\n",
    "                    color=color,\n",
    "                ),\n",
    "                cmap=get_cmap(mask_imgs),\n",
    "                alpha=alpha,\n",
    "            )\n",
    "            axes[m, 2].set_axis_off()\n",
    "        im_id += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#<-----\n",
    "#plot_imgs(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=10, figsize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T17:52:13.083763Z",
     "start_time": "2023-01-11T17:52:13.078220Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loadImgs(path_list, mode, img_channels):\n",
    "    imgs = []\n",
    "    nomes = []\n",
    "    for path in path_list:\n",
    "        files = os.listdir(path)\n",
    "        files.sort()\n",
    "        print(\"\\npath:\", path, \" len(files):\", len(files))\n",
    "        for file in files:\n",
    "            imgPath = os.path.join(path, file)\n",
    "\n",
    "            #print(\"loanding img:\",len(imgs), imgPath)\n",
    "            img = cv2.imread(imgPath, mode) # TODO check need mode 0 to img mask\n",
    "\n",
    "            if mode == 0:\n",
    "                img = np.expand_dims(img, 2)\n",
    "            img = img / float(255)\n",
    "            imgs.append(img)\n",
    "            nomes.append(file)\n",
    "\n",
    "    return np.array(imgs), nomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-11T17:52:14.840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = \"/media/sda2/home/j/Downloads/0del/00/iv_dl_tests/Recortes/\"\n",
    "#path = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/\"\n",
    "\n",
    "base_train = \"A\"\n",
    "img_channels = 3\n",
    "\n",
    "path_predict = \"/media/sda2/home/j/Downloads/0del/00/iv_dl_tests/Teste_01E/result-images/\"\n",
    "#path_predict = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/Teste_01E/result-images/\"\n",
    "\n",
    "trainImgs,nomes = loadImgs([path + 'Base_' + base_train + '/'], 1, img_channels)\n",
    "validImgs,nomes = loadImgs([path + 'Base_' + base_train + '_mask/'], 0, img_channels)\n",
    "prImgs,nomes = loadImgs([path_predict], 0, img_channels)\n",
    "print(\"\\nLoaded images!\")\n",
    "\n",
    "\n",
    "## overlay ori_imgs vs mask\n",
    "#plot_imgs_jb(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=5,\n",
    "#          red_imgs = prImgs, figsize=6, overlay=\"org_imgs\")\n",
    "\n",
    "## overlay mask vs predict\n",
    "# plot_imgs_jb(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=2,\n",
    "#             pred_imgs = prImgs, figsize=8, overlay=\"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T11:26:45.604559Z",
     "start_time": "2023-01-10T11:26:40.907188Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plots = len(imgs)\n",
    "\n",
    "plot_imgs(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=10, figsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T08:28:00.930276Z",
     "start_time": "2022-09-30T08:28:00.919890Z"
    }
   },
   "source": [
    "## plot_imgs_jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T01:28:29.217254Z",
     "start_time": "2023-07-17T01:28:29.149530Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_imgs_jb(org_imgs, mask_imgs, pred_imgs = None, nm_img_to_plot = 10, figsize = 4, alpha = 0.5,\n",
    "                 color = \"red\", overlay = \"\", count_star = 0, show_plot = True, save_plot = False,\n",
    "                 path_save = \"\", lang_val = \"pt\", new_test = \"\", structuring_element = \"\", pr_morphs = None):\n",
    "    \"\"\"\n",
    "    Image plotting for semantic segmentation data.\n",
    "    Last column is always an overlay of ground truth or prediction\n",
    "    depending on what was provided as arguments.\n",
    "    Args:\n",
    "        org_imgs (numpy.ndarray): Array of arrays representing a collection of original images.\n",
    "        mask_imgs (numpy.ndarray): Array of arrays representing a collection of mask images (grayscale).\n",
    "        pred_imgs (numpy.ndarray, optional): Array of arrays representing a collection of prediction masks\n",
    "                                             images.. Defaults to None.\n",
    "        nm_img_to_plot (int, optional): How many images to display. Takes first N images. Defaults to 10.\n",
    "        figsize (int, optional): Matplotlib figsize. Defaults to 4.\n",
    "        alpha (float, optional): Transparency for mask overlay on original image. Defaults to 0.5.\n",
    "        color (str, optional): Color for mask overlay. Defaults to \"red\".\n",
    "        lang_val (str, optional): language of info in plots \"pt\" or \"en\". Defaults is \"pt\"\n",
    "        other_test (srt, optional): the name of third colum of images in plots. A new/other \"test\"\n",
    "        structuring_element (srt, optional): the structuring element in third colum of images in plots.\n",
    "                                             A new/other \"test\"\n",
    "    \"\"\" # NOQA E501\n",
    "    assert(color in MASK_COLORS)\n",
    "\n",
    "    #from matplotlib import rcParams\n",
    "    #rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "    #lang_val = \"pt\" # pt or en\n",
    "    if lang_val == \"pt\":\n",
    "        field_1 = \"Imagem original\"\n",
    "        field_2 = \"Marcação feita \\n pelo especialista\"\n",
    "        field_3 = \"Predição\"\n",
    "\n",
    "        if new_test == \"\": # 4 cols\n",
    "            field_4 = \"Sobreposição\\n\"\n",
    "            ind_3 = 3\n",
    "        else: # 5 cols\n",
    "            field_4 = new_test\n",
    "            field_5 = \"Sobreposição\\n\"\n",
    "            ind_3 = 4\n",
    "\n",
    "        label_TP= \"VP\"\n",
    "        label_TN= \"VN\"\n",
    "    else:\n",
    "        field_1 = \"Original\"\n",
    "        field_2 = \"Ground truth\"\n",
    "\n",
    "        if new_test == \"\":\n",
    "            field_3 = \"Prediction\"\n",
    "        else:\n",
    "            field_3 = new_test\n",
    "\n",
    "        field_4 = \"Overlay\"\n",
    "        label_TP= \"TP\"\n",
    "        label_TN= \"TN\"\n",
    "\n",
    "    if nm_img_to_plot > org_imgs.shape[0]:\n",
    "        nm_img_to_plot = org_imgs.shape[0]\n",
    "\n",
    "    im_id = 0\n",
    "    org_imgs_size = org_imgs.shape[1]\n",
    "\n",
    "    org_imgs = reshape_arr(org_imgs)\n",
    "    mask_imgs = reshape_arr(mask_imgs)\n",
    "    if not (pred_imgs is None):\n",
    "        cols = 4\n",
    "        pred_imgs = reshape_arr(pred_imgs)\n",
    "\n",
    "        if new_test != \"\":\n",
    "            cols = 5\n",
    "    else:\n",
    "        cols = 3\n",
    "\n",
    "    fig, axes = plt.subplots(nm_img_to_plot, cols, figsize = (cols * figsize, nm_img_to_plot * figsize),\n",
    "                             squeeze = False, constrained_layout = True)\n",
    "\n",
    "    #if new_test == \"\":\n",
    "        #fig.tight_layout()\n",
    "    #if new_test != '':\n",
    "        #fig.tight_layout(h_pad = 5, w_pad = 5)\n",
    "        #fig.tight_layout(h_pad = 0.5, w_pad = 0.2)\n",
    "        #plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "\n",
    "    font_size = 30\n",
    "    print(f\"{count_star = }\")\n",
    "\n",
    "    if overlay == \"org_imgs\":\n",
    "        print(\"\\n# overlay ori_imgs vs mask\\n\")\n",
    "        pad_value = 0\n",
    "    else:\n",
    "        print(\"\\n# overlay mask vs predict\\n\")\n",
    "        #pad_value = 60\n",
    "        pad_value = 50\n",
    "\n",
    "    print(\"count:\", end = \" \")\n",
    "\n",
    "    #axes[0, 0].set_title(\"Original\", fontsize = font_size, pad = pad_value)\n",
    "    axes[0, 0].set_title(field_1, fontsize = font_size, pad = pad_value)\n",
    "\n",
    "    #axes[0, 1].set_title(\"Ground truth\", fontsize = font_size, pad = pad_value)\n",
    "    axes[0, 1].set_title(field_2, fontsize = font_size, pad = pad_value)\n",
    "    if not (pred_imgs is None):\n",
    "        #axes[0, 2].set_title(\"Prediction\", fontsize = font_size, pad = pad_value)\n",
    "        axes[0, 2].set_title(field_3, fontsize = font_size, pad = pad_value)\n",
    "\n",
    "        #axes[0, 3].set_title(\"Overlay\", fontsize = font_size, pad = pad_value)\n",
    "        axes[0, 3].set_title(field_4, fontsize = font_size, pad = pad_value)\n",
    "\n",
    "        if new_test != \"\":\n",
    "            axes[0, 4].set_title(field_5, fontsize = font_size, pad = pad_value)\n",
    "\n",
    "    else:\n",
    "        #axes[0, 2].set_title(\"Overlay\", fontsize = font_size, pad = pad_value)\n",
    "        axes[0, 2].set_title(field_4, fontsize = font_size, pad = pad_value)\n",
    "\n",
    "    for m in range(0, nm_img_to_plot):\n",
    "        print(m + 1, end = \" \")\n",
    "\n",
    "        img_org = org_imgs[im_id]\n",
    "        img_org = img_org[...,::-1] # BGR to RGB\n",
    "\n",
    "#         axes[m, 0].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "        axes[m, 0].imshow(img_org, cmap=get_cmap(org_imgs))\n",
    "\n",
    "        axes[m, 0].set_axis_off()\n",
    "\n",
    "        mask_img = mask_imgs[im_id].copy()\n",
    "\n",
    "        mask_img[mask_img >= 0.5] = 1\n",
    "        mask_img[mask_img < 1] = 0\n",
    "        mask_img = mask_img.astype('uint8')\n",
    "        #print(\"Max mask_img:\", np.max(mask_img))\n",
    "\n",
    "#         axes[m, 1].imshow(mask_imgs[im_id], cmap=get_cmap(mask_imgs))\n",
    "        axes[m, 1].imshow(mask_img, cmap=get_cmap(mask_imgs))\n",
    "\n",
    "        axes[m, 1].set_axis_off()\n",
    "        if not (pred_imgs is None):\n",
    "            pr_img = pred_imgs[im_id].copy()\n",
    "\n",
    "            pr_img[pr_img >= 0.5] = 1\n",
    "            pr_img[pr_img < 1] = 0\n",
    "            pr_img = pr_img.astype('uint8')\n",
    "            #print(\"Max pr_img:\", np.max(pr_img))\n",
    "\n",
    "            #axes[m, 2].imshow(pred_imgs[im_id], cmap=get_cmap(pred_imgs))\n",
    "            axes[m, 2].imshow(pr_img, cmap=get_cmap(pred_imgs))\n",
    "\n",
    "            if new_test != \"\":\n",
    "                #text_op_morph = ''\n",
    "                if m == 0: text_op_morph = \"Dilatação\"\n",
    "                elif m == 1: text_op_morph = \"Erosão\"\n",
    "                elif m == 2: text_op_morph = \"Abertura\"\n",
    "                elif m == 3: text_op_morph = \"Fechamento\"\n",
    "\n",
    "                #structuring_element = \" + Todos_1\"\n",
    "                #structuring_element = \" + Cruz\"\n",
    "\n",
    "                #text_op_morph = text_op_morph + \" + \" + structuring_element\n",
    "                text_op_morph = text_op_morph\n",
    "                print(\"structuring_element: \", structuring_element)\n",
    "\n",
    "                    #MORPH_CLOSE_allOne\n",
    "                    #MORPH_CLOSE_cross\n",
    "                    #MORPH_DILATE_allOne\n",
    "                    #MORPH_DILATE_cross\n",
    "                    #MORPH_ERODE_allOne\n",
    "                    #MORPH_ERODE_cross\n",
    "                    #MORPH_OPEN_allOne\n",
    "                    #MORPH_OPEN_cross\n",
    "\n",
    "                #axes[m, 3].text(50, -10, text_op_morph, fontsize=30)\n",
    "                axes[m, 3].text(100, -10, text_op_morph, fontsize=30)\n",
    "\n",
    "            axes[m, 2].set_axis_off()\n",
    "\n",
    "#             print(\"get_cmap(org_imgs):\", get_cmap(org_imgs))\n",
    "#             print(\"get_cmap(mask_imgs):\", get_cmap(mask_imgs))\n",
    "#             print(\"get_cmap(pred_imgs):\", get_cmap(pred_imgs))\n",
    "\n",
    "            if overlay == \"org_imgs\":\n",
    "                axes[m, 3].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "\n",
    "                axes[m, 3].imshow(mask_to_rgba(\n",
    "#                                 zero_pad_mask(pred_imgs[im_id], desired_size=org_imgs_size),\n",
    "                                zero_pad_mask(mask_imgs[im_id], desired_size=org_imgs_size),\n",
    "                                color=color), cmap=get_cmap(pred_imgs), alpha=alpha)\n",
    "\n",
    "            else: # overlay == \"mask_imgs\":\n",
    "#                 axes[m, 3].imshow(mask_imgs[im_id], cmap=get_cmap(mask_imgs))\n",
    "#                 axes[m, 3].imshow(pred_imgs[im_id], cmap=get_cmap(mask_imgs))\n",
    "\n",
    "                if not (pr_morphs is None):\n",
    "                    pr_img = pr_morphs[im_id].copy()\n",
    "\n",
    "                    pr_img[pr_img >= 0.5] = 1\n",
    "                    pr_img[pr_img < 1] = 0\n",
    "                    pr_img = pr_img.astype('uint8')\n",
    "                    #print(\"Max pr_img:\", np.max(pr_img))\n",
    "\n",
    "                    #axes[m, 2].imshow(pred_imgs[im_id], cmap=get_cmap(pred_imgs))\n",
    "                    axes[m, 3].imshow(pr_img, cmap=get_cmap(pred_imgs))\n",
    "\n",
    "                    axes[m, 3].set_axis_off()\n",
    "\n",
    "                dim0 = pr_img.shape[0]\n",
    "                dim1 = pr_img.shape[1]\n",
    "                zeros = np.zeros((dim0, dim1))\n",
    "                img_result = np.stack((zeros, zeros, zeros), axis=-1)\n",
    "\n",
    "                img_result = img_result.astype('uint8')\n",
    "#                 print(\"pr_img.shape:\", pr_img.shape)\n",
    "#                 print(\"mask_img.shape:\", mask_img.shape)\n",
    "\n",
    "#                 print(\"img_result.shape:\", img_result.shape)\n",
    "#                 print(\"img_result.dtype:\", img_result.dtype)\n",
    "\n",
    "                i = 0\n",
    "                while i < dim0:\n",
    "                    #print(\"i\", i)\n",
    "                    j = 0\n",
    "                    while j < dim1:\n",
    "                        #print(\"j\", j)\n",
    "                        if mask_img[i][j] == pr_img[i][j]:\n",
    "                            if pr_img[i][j] == 1: # True Positive\n",
    "                                img_result[i][j] = (255, 255, 255) # white\n",
    "                            else: # True Negative\n",
    "                                img_result[i][j] = (0, 0, 0) # black\n",
    "                        else:\n",
    "                            if pr_img[i][j] == 1: # False Positive\n",
    "                                img_result[i][j] = (255, 0, 0) # red\n",
    "                            else: # False Negative\n",
    "                                img_result[i][j] = (0, 0, 255) # blue FN\n",
    "\n",
    "                        j += 1\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "#                 print(\"img_result:\", img_result)\n",
    "#                 cv2.imwrite(\"img_result.png\", img_result)\n",
    "\n",
    "                axes[m, ind_3].imshow(img_result)\n",
    "\n",
    "                if im_id == 0:\n",
    "                    import matplotlib.patches as mpatches\n",
    "#                     import matplotlib.pyplot as plt\n",
    "\n",
    "                    white_patch = mpatches.Patch(color = \"white\", label = label_TP)\n",
    "                    black_patch = mpatches.Patch(color = \"black\", label = label_TN)\n",
    "                    red_patch = mpatches.Patch(color = \"red\", label = \"FP\")\n",
    "                    blue_patch = mpatches.Patch(color = \"blue\", label = \"FN\")\n",
    "\n",
    "                    axes[m, ind_3].legend(handles=[white_patch, black_patch, red_patch, blue_patch],\n",
    "                                bbox_to_anchor=(0, 1, 1, 0.2), loc = \"lower center\", ncol = 4,\n",
    "                                fontsize = font_size - 10, facecolor = '#EEEEEE', framealpha = 1)\n",
    "\n",
    "            axes[m, ind_3].set_axis_off()\n",
    "\n",
    "        else:\n",
    "            img_org_2 = org_imgs[im_id]\n",
    "            img_org_2 = img_org_2[...,::-1] # BGR to RGB\n",
    "\n",
    "            #axes[m, 2].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "            axes[m, 2].imshow(img_org_2, cmap=get_cmap(org_imgs))\n",
    "\n",
    "            mask_img_2 = mask_imgs[im_id].copy()\n",
    "\n",
    "            mask_img_2[mask_img_2 >= 0.5] = 1\n",
    "            mask_img_2[mask_img_2 < 1] = 0\n",
    "            mask_img_2 = mask_img_2.astype('uint8')\n",
    "\n",
    "            axes[m, 2].imshow(\n",
    "                mask_to_rgba(\n",
    "                    #zero_pad_mask(mask_imgs[im_id], desired_size=org_imgs_size),\n",
    "                    zero_pad_mask(mask_img_2, desired_size=org_imgs_size),\n",
    "                    color=color,\n",
    "                ),\n",
    "                cmap=get_cmap(mask_imgs),\n",
    "                alpha=alpha,\n",
    "            )\n",
    "            axes[m, 2].set_axis_off()\n",
    "        im_id += 1\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "    if save_plot:\n",
    "        if path_save == '':\n",
    "            path_save = os.getcwd()\n",
    "\n",
    "        file_name = \"p_\" + str(count_star) + \"_\" + overlay + \"_SE_\" + structuring_element + \".pdf\"\n",
    "\n",
    "        print(\"Saving img in:\", path_save)\n",
    "        print(\"file name:\", file_name)\n",
    "\n",
    "        fig_dpi = 50 # default is 100\n",
    "\n",
    "        #fig.savefig(path_save + \"plot_imgs_jb_\" + str(count_star) + \".png\", dpi = fig.dpi) # Save plots\n",
    "        #fig.savefig(path_save + \"p_\" + str(count_star) + \"_\" + overlay + \".pdf\", dpi = fig_dpi)\n",
    "        fig.savefig(path_save + '/' + file_name, dpi = fig_dpi, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## load_selected_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T23:49:18.061780Z",
     "start_time": "2023-07-16T23:49:18.046891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_selected_imgs(path, list_img, mode):\n",
    "    print(f\"\\npath: {path} len(list_img): {len(list_img)}\")\n",
    "\n",
    "    imgs = []\n",
    "    for file in list_img:\n",
    "        img_path = os.path.join(path, file)\n",
    "        #print(f\"img_path: {img_path}\")\n",
    "        img = cv2.imread(img_path, mode)\n",
    "\n",
    "        #print(\"Max:\", np.max(img))\n",
    "        if mode == 0:\n",
    "            img = np.expand_dims(img, 2)\n",
    "\n",
    "        img = img / float(255)\n",
    "        imgs.append(img)\n",
    "\n",
    "    return np.array(imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## load dataset A to E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T23:49:22.988223Z",
     "start_time": "2023-07-16T23:49:19.907665Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#path = \"/media/sda2/home/j/Downloads/0del/00/iv_dl_tests/Recortes/\"\n",
    "#path = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/\"\n",
    "path = \"/run/media/j/Files_ex/0_f_mest_bkp/datasets/Recortes/\"\n",
    "\n",
    "test_use = 9 # 1 or 9\n",
    "\n",
    "path_predict = \"/media/sda2/home/j/Downloads/0del/00/iv_dl_tests/Teste_0\" + str(test_use) + \"E/result-images/\"\n",
    "#path_predict = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/Teste_01E/result-images/\"\n",
    "path_predict = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/iv_results/results_E_1/\"\n",
    "path_predict = path_predict + \"test_\" + str(test_use) + \"_U-Net_without_VI_weights_Base_E/result_images/predict_Base_E/\"\n",
    "\n",
    "base_train = \"E\"\n",
    "\n",
    "# cro 1, 3, 30, 133, 245, 378, 430, 503, 504,\n",
    "# b 2 13 242 428 488 819 916\n",
    "\n",
    "##list_img = (\"A_0001.png\", \"A_0030.png\", \"A_0041.png\", \"A_0133.png\",\n",
    "##            \"A_0503.png\", \"B_0916.png\", \"C_0274.png\", \"D_1819.png\") # Used in the paper with test 9\n",
    "#list_img = (\"A_0001.png\", \"A_0030.png\", \"A_0041.png\", \"A_0133.png\", \"A_0503.png\")\n",
    "\n",
    "##list_img = (\"B_0013.png\", \"B_0242.png\", \"B_0428.png\", \"B_0488.png\", \"B_0819.png\", \"B_0916.png\")\n",
    "\n",
    "#list_img = (\"A_0103.png\", \"B_0002.png\", \"C_0002.png\", \"D_0003.png\")\n",
    "\n",
    "#list_img = (\"C_0083.png\", \"C_0242.png\", \"C_0163.png\", \"C_0274.png\", \"C_0288.png\", \"C_1007.png\")\n",
    "\n",
    "list_img = (\"C_0083.png\", \"C_0163.png\", \"C_0274.png\", \"C_0288.png\", \"C_1007.png\")\n",
    "\n",
    "imgs = load_selected_imgs(path + 'Base_' + base_train + '/', list_img, 1)\n",
    "masks = load_selected_imgs(path + 'Base_' + base_train + '_mask/', list_img, 0)\n",
    "pr_imgs = load_selected_imgs(path_predict, list_img, 0)\n",
    "\n",
    "print(\"\\nImages loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load dataset Lapix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T13:53:28.872466Z",
     "start_time": "2023-07-16T13:53:28.172008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lapix\n",
    "\n",
    "path = \"/run/media/j/Files_ex/0_f_mest_bkp/datasets/Recortes/\"\n",
    "\n",
    "start = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/new_04_01_2023/results_L/\"\n",
    "\n",
    "#folder_user = \"test_9_U-Net_without_VI_weights_Base_E/\" # Weight Base E\n",
    "folder_user = \"test_9_U-Net_without_VI_weights_Base_L/\" # Weight Base L\n",
    "\n",
    "path_predict = start + folder_user + \"result_images/predict_Base_L/\"\n",
    "\n",
    "list_img = (\"sugarcane1_0115.png\" , \"sugarcane1_0202.png\", \"sugarcane1_0322.png\")\n",
    "\n",
    "# To create a tuple with only one item, have add a comma after the item,\n",
    "# otherwise Python will recognize the variable as str\n",
    "list_img = (\"sugarcane1_0793.png\",)\n",
    "\n",
    "list_img = (\"sugarcane1_0793.png\", \"sugarcane1_0115.png\" , \"sugarcane1_0202.png\", \"sugarcane1_0322.png\")\n",
    "\n",
    "base_train = \"L\"\n",
    "\n",
    "imgs = load_selected_imgs(path + 'Base_' + base_train + '/', list_img, 1)\n",
    "masks = load_selected_imgs(path + 'Base_' + base_train + '_mask/', list_img, 0)\n",
    "pr_imgs = load_selected_imgs(path_predict, list_img, 0)\n",
    "\n",
    "print(\"\\nImages loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T23:58:01.876716Z",
     "start_time": "2023-07-16T23:57:54.580764Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots = len(imgs) # 5 imagens to good paper size\n",
    "#plots = 4 # 5 imagens to good paper size\n",
    "\n",
    "lang = \"pt\" # pt or en\n",
    "#lang = \"en\"\n",
    "\n",
    "save_plot_l = True # save plot local variable\n",
    "save_plot_l = False\n",
    "\n",
    "## overlay ori_imgs vs mask - pred_imgs is None\n",
    "plot_imgs_jb(org_imgs = imgs, mask_imgs = masks, nm_img_to_plot = plots,\n",
    "                figsize = 6, overlay = \"org_imgs\", save_plot = save_plot_l,\n",
    "                path_save = \"\", lang_val = lang)\n",
    "\n",
    "## overlay mask vs predict\n",
    "#plot_imgs_jb(org_imgs = imgs, mask_imgs = masks, nm_img_to_plot = plots, pred_imgs = pr_imgs, figsize = 8,\n",
    "#            overlay = \"mask\", save_plot = save_plot_l,\n",
    "#            path_save = \"\",lang_val = lang)\n",
    "\n",
    "plot_imgs_jb(org_imgs = imgs, mask_imgs = masks, nm_img_to_plot = plots, pred_imgs = pr_imgs, figsize = 7,\n",
    "            overlay = \"mask\", count_star = 0, show_plot = True, save_plot = save_plot_l,\n",
    "            path_save = \"\", lang_val = lang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## morphological operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T00:20:51.490948Z",
     "start_time": "2023-07-17T00:20:50.769493Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_selected_imgs_morph(path, img_name, mode):\n",
    "    #print(f\"\\npath: {path} len(list_img): {len(list_img)}\")\n",
    "\n",
    "    imgs = []\n",
    "    #for file in list_img:\n",
    "        #img_path = os.path.join(path, file)\n",
    "    img_path = os.path.join(path, img_name)\n",
    "\n",
    "    print(f\"img_path: {img_path}\")\n",
    "    img = cv2.imread(img_path, mode)\n",
    "\n",
    "    #print(\"Max:\", np.max(img))\n",
    "    if mode == 0:\n",
    "        img = np.expand_dims(img, 2)\n",
    "\n",
    "    img = img / float(255)\n",
    "    #imgs.append(img)\n",
    "\n",
    "    #return np.array(imgs)\n",
    "    return img\n",
    "\n",
    "#path = \"/media/sda2/home/j/Downloads/0del/00/iv_dl_tests/Recortes/\"\n",
    "#path = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/\"\n",
    "path = \"/run/media/j/Files_ex/0_f_mest_bkp/datasets/Recortes/\"\n",
    "\n",
    "#test_use = 9 # 1 or 9\n",
    "#test_use = 1 # 1 or 9\n",
    "\n",
    "#path_predict = \"/media/sda2/home/j/Downloads/0del/00/iv_dl_tests/Teste_0\" + str(test_use) + \"E/result-images/\"\n",
    "#path_predict = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/Teste_01E/result-images/\"\n",
    "\n",
    "#MORPH_CLOSE_allOne\n",
    "#MORPH_CLOSE_cross\n",
    "#MORPH_DILATE_allOne\n",
    "#MORPH_DILATE_cross\n",
    "#MORPH_ERODE_allOne\n",
    "#MORPH_ERODE_cross\n",
    "#MORPH_OPEN_allOne\n",
    "#MORPH_OPEN_cross\n",
    "\n",
    "base_train = \"E\"\n",
    "#base_train = \"L\"\n",
    "\n",
    "if base_train == \"E\":\n",
    "    path_predict = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/iv_results/results_E_1/\"\n",
    "    path_predict = path_predict  + \"test_1_U-Net_without_VI_weights_Base_E/result_images/predict_Base_E/\"\n",
    "\n",
    "    # cro 1, 3, 30, 133, 245, 378, 430, 503, 504,\n",
    "    # b 2 13 242 428 488 819 916\n",
    "\n",
    "    #list_img = (\"A_0001.png\", \"A_0030.png\", \"A_0041.png\", \"A_0133.png\",\n",
    "    #            \"A_0503.png\", \"B_0916.png\", \"C_0274.png\", \"D_1819.png\") # Used in the paper with test 9\n",
    "    #list_img = (\"A_0001.png\", \"A_0030.png\", \"A_0041.png\", \"A_0133.png\", \"A_0503.png\")\n",
    "\n",
    "    #list_img = (\"B_0013.png\", \"B_0242.png\", \"B_0428.png\", \"B_0488.png\", \"B_0819.png\", \"B_0916.png\")\n",
    "\n",
    "    #list_img = (\"C_0083.png\", \"C_0242.png\", \"C_0163.png\", \"C_0274.png\", \"C_0288.png\", \"C_1007.png\")\n",
    "    #list_img = (\"C_0083.png\", \"C_0163.png\", \"C_0274.png\", \"C_0288.png\", \"C_1007.png\")\n",
    "\n",
    "    #list_img = (\"C_1298.png\", \"C_1266.png\", \"C_1206.png\", \"C_1481.png\")\n",
    "\n",
    "    list_img = (\"A_0063.png\", \"A_0078.png\", \"A_0114.png\", \"B_0650.png\")\n",
    "\n",
    "elif base_train == \"L\":\n",
    "    path_predict = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/new_04_01_2023/results_L/\"\n",
    "    path_predict = path_predict  + \"test_9_U-Net_without_VI_weights_Base_L/result_images/predict_Base_L/\"\n",
    "\n",
    "    #list_img = (\"sugarcane1_0793.png\", \"sugarcane1_0115.png\" , \"sugarcane1_0202.png\", \"sugarcane1_0322.png\")\n",
    "    list_img = (\"sugarcane1_0241.png\", \"sugarcane1_0162.png\" , \"sugarcane1_0163.png\", \"sugarcane1_0282.png\")\n",
    "\n",
    "imgs = load_selected_imgs(path + 'Base_' + base_train + '/', list_img, 1)\n",
    "masks = load_selected_imgs(path + 'Base_' + base_train + '_mask/', list_img, 0)\n",
    "pr_imgs = load_selected_imgs(path_predict, list_img, 0)\n",
    "\n",
    "num_ele = 1\n",
    "#num_ele = 2\n",
    "\n",
    "if num_ele == 1:\n",
    "    structuring_element_l_en = \"cross\" #\" + Cruz\"\n",
    "    structuring_element_l = \"Cruz\"\n",
    "else:\n",
    "    structuring_element_l_en = \"allOne\" #\" + Todos_1\"\n",
    "    structuring_element_l = \"Todos_1\"\n",
    "\n",
    "img_op_morph = []\n",
    "for i in range(4):\n",
    "    #if new_test != \"\":\n",
    "    #text_op_morph = ''\n",
    "    if i == 0: operation = \"DILATE\" #text_op_morph = \"Dilatação\"\n",
    "    elif i == 1: operation = \"ERODE\" #text_op_morph = \"Erosão\"\n",
    "    elif i == 2: operation = \"OPEN\" #text_op_morph = \"Abertura\"\n",
    "    elif i == 3: operation = \"CLOSE\" # text_op_morph = \"Fechamento\"\n",
    "\n",
    "    #operation = \"ERODE\"\n",
    "    #text_op_morph = text_op_morph + structuring_element_l_en\n",
    "\n",
    "    operation_morph = \"MORPH_\" + operation+ \"_\" + structuring_element_l_en\n",
    "    print(\"\\noperation_morph: \", operation_morph)\n",
    "    print(\"Image name:\", list_img[i])\n",
    "    img_name = list_img[i]\n",
    "\n",
    "    #path_predict = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/new_15_01_2023/test_1_U-Net_without_VI_weights_Base_E\"\n",
    "    #path_predict = path_predict + \"/result_images/\" + operation_morph + \"/predict_Base_E/\"\n",
    "\n",
    "    if base_train == \"E\":\n",
    "        path_pr_morph = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/iv_results/results_E_1/\"\n",
    "        path_pr_morph = path_pr_morph + \"test_1_U-Net_without_VI_weights_Base_E/result_images/\"\n",
    "        path_pr_morph = path_pr_morph + operation_morph + \"/predict_Base_E/\"\n",
    "\n",
    "    elif base_train == \"L\":\n",
    "        path_pr_morph = \"/run/media/j/Files_ex/0_f_mest_bkp_outros/new_04_01_2023/results_L/\"\n",
    "        path_pr_morph = path_pr_morph + \"test_9_U-Net_without_VI_weights_Base_L/result_images/\"\n",
    "        path_pr_morph = path_pr_morph + operation_morph + \"/predict_Base_L/\"\n",
    "\n",
    "    #print(\"path_pr_morph:\", path_pr_morph)\n",
    "\n",
    "    img_op_morph.append(load_selected_imgs_morph(path_pr_morph, img_name, 0))\n",
    "    #pr_imgs = pr_imgs + load_selected_imgs_morph(path_predict, list_img[i], 0)\n",
    "\n",
    "pr_imgs_morph = np.array(img_op_morph)\n",
    "\n",
    "print(\"\\nImages loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T01:33:29.308257Z",
     "start_time": "2023-07-17T01:33:24.624247Z"
    }
   },
   "outputs": [],
   "source": [
    "#plots = len(imgs) # 5 imagens to good paper size\n",
    "plots = 4 # 5 imagens to good paper size\n",
    "\n",
    "lang = \"pt\" # pt or en\n",
    "#lang = \"en\"\n",
    "\n",
    "save_plot_l = True # save plot local variable\n",
    "save_plot_l = False\n",
    "\n",
    "new_test_l = \"Predição + Operação\\nMorfológica de:\" # new test local name\n",
    "\n",
    "## overlay ori_imgs vs mask - pred_imgs is None\n",
    "#plot_imgs_jb(org_imgs = imgs, mask_imgs = masks, nm_img_to_plot = plots,\n",
    "#             figsize = 6, overlay = \"org_imgs\", save_plot = save_plot_l,\n",
    "#             path_save = \"\", lang_val = lang)\n",
    "\n",
    "## overlay mask vs predict\n",
    "#plot_imgs_jb(org_imgs = imgs, mask_imgs = masks, nm_img_to_plot = plots,\n",
    "#             pred_imgs = pr_imgs, figsize = 8, overlay = \"mask\", save_plot = save_plot_l,\n",
    "#             path_save = \"\",lang_val = lang)\n",
    "\n",
    "## predict + morphs\n",
    "plot_imgs_jb(org_imgs = imgs, mask_imgs = masks, nm_img_to_plot = plots, pred_imgs = pr_imgs, figsize = 8,\n",
    "             overlay = \"mask\", count_star = 0, show_plot = True, save_plot = save_plot_l,\n",
    "             path_save = '', lang_val = lang, new_test = new_test_l,\n",
    "             structuring_element = structuring_element_l, pr_morphs = pr_imgs_morph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot many imgs and save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T18:18:12.099215Z",
     "start_time": "2023-07-16T18:16:42.703276Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#plot_imgs(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=5,\n",
    "#          pred_imgs = prImgs, figsize=6)\n",
    "\n",
    "## overlay ori_imgs vs mask\n",
    "#plot_imgs_jb(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=5,\n",
    "#             red_imgs = prImgs, figsize=6, overlay=\"org_imgs\")\n",
    "\n",
    "## overlay mask vs predict\n",
    "# plot_imgs_jb(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=2,\n",
    "#              pred_imgs = prImgs, figsize=8, overlay=\"mask\")\n",
    "\n",
    "#path_save_plot = \"\"\n",
    "path_save_plot = \"/run/media/j/Files_ex/00_tmp/0del/\"\n",
    "\n",
    "plots = 5\n",
    "i = 0\n",
    "\n",
    "list_img_2 = []\n",
    "files = os.listdir(path + 'Base_' + base_train + '/')\n",
    "files.sort()\n",
    "\n",
    "print(\"\\npath:\", path, \" len(files):\", len(files))\n",
    "for file in files:\n",
    "    #print(\"file:\", file)\n",
    "    list_img_2.append(file)\n",
    "\n",
    "#save_plot_l = True\n",
    "save_plot_l = False\n",
    "\n",
    "b1 = 500 # 0\n",
    "#list_img_2 = list_img_2[b1:end]\n",
    "list_img_2 = list_img_2[b1:]\n",
    "\n",
    "#stop_num = len(list_img_2)\n",
    "stop_num = 100 # 100\n",
    "\n",
    "while i < len(list_img_2):\n",
    "    print(f\"\\n{i = }\")\n",
    "    start = i\n",
    "    end = i + plots\n",
    "\n",
    "    list_img_tmp = list_img_2[start:end]\n",
    "\n",
    "    org = load_selected_imgs(path + 'Base_' + base_train + '/', list_img_tmp, 1)\n",
    "    mask = load_selected_imgs(path + 'Base_' + base_train + '_mask/', list_img_tmp, 0)\n",
    "    pred = load_selected_imgs(path_predict, list_img_tmp, 0)\n",
    "\n",
    "    #n_plot = len(imgs)\n",
    "\n",
    "    #for j,v in zip(range(1, plots + 1), list_img_2[start:end]):\n",
    "    for j,v in zip(range(1, plots + 1), list_img_tmp):\n",
    "        print(j, v, end = \" \")\n",
    "\n",
    "    plot_imgs_jb(org_imgs = org, mask_imgs = mask, nm_img_to_plot = plots, pred_imgs = pred, figsize = 7,\n",
    "            overlay = \"mask\", count_star = i, show_plot = True, save_plot = save_plot_l,\n",
    "            path_save = path_save_plot, lang_val = lang)\n",
    "\n",
    "    # plot_imgs_jb(org_imgs = org, mask_imgs = mask, nm_img_to_plot = plots,\n",
    "    #              pred_imgs = pred, figsize = 8, overlay = \"org_imgs\")\n",
    "\n",
    "    i += plots\n",
    "    print(\"All plots done!\")\n",
    "\n",
    "    if i > stop_num:\n",
    "        break\n",
    "#     input()\n",
    "\n",
    "    ## clear output\n",
    "    #from IPython.display import clear_output\n",
    "    #clear_output(wait = False)\n",
    "\n",
    "print(\"\\nAll done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Vegetation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:07.256216Z",
     "start_time": "2023-01-15T23:04:07.232252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vi_names = [[\"01_VARI\", \"Visible Atmospherically Resistant Index\"],\n",
    "            [\"02_ExG\", \"Excess Green Index\"],\n",
    "            [\"03_ExR\", \"Excess Red Vegetation Index\"],\n",
    "            [\"04_ExB\", \"Excess Blue Vegetation Index\"],\n",
    "            [\"05_EXGR\", \"Excess Green minus Excess Red\"],\n",
    "            [\"06_GRVI\", \"Green Red Vegetation Index\"],\n",
    "            [\"07_MGRVI\", \"Modified Green Red Vegetation Index\"],\n",
    "            [\"08_GLI\", \"Green Leaf Index\"],\n",
    "            [\"09_RGBVI\", \"Red Green Blue Vegetation Index\"],\n",
    "            [\"10_IKAW\", \"Kawashima Index\"]]\n",
    "\n",
    "def split_RGB_channel(img): # return RGB channels\n",
    "    ## img.dtype: uint8\n",
    "    ## pixel with value 0, if 0 + 1 => 1\n",
    "    ## pixel with value 255, if 255 + 1 => 0\n",
    "\n",
    "    ## Set 1 if the value is 0\n",
    "    ## Lower number of nan if calculus were backgroud was 0\n",
    "    img [img == 0] = 1\n",
    "\n",
    "    # opencv reads the images as BGR instead of RGB\n",
    "    B, G, R = cv2.split(img)\n",
    "\n",
    "    # Convert to float - 0 the sum is more then 255\n",
    "    R = R.astype('float32')\n",
    "    G = G.astype('float32')\n",
    "    B = B.astype('float32')\n",
    "\n",
    "    return R, G, B\n",
    "\n",
    "def check_value_inf_nan(nameValue, value): # check if value is inf or nan\n",
    "    ## numpy.ndarray\n",
    "    ## 0/0 = nan\n",
    "    ## >0/0 = inf, <0/0 = -inf\n",
    "    ## 0/1 = 0.0\n",
    "\n",
    "    #if np.isnan(np.min(value)) or np.isinf(np.max(value)):\n",
    "    if np.isnan(np.min(value)) or np.isinf(np.max(value)) or np.isnan(np.max(value)) or np.isinf(np.min(value)):\n",
    "        print(\"\\ncheck_value_inf_nan {}\".format(nameValue))\n",
    "        print(\"np.max({}): {} np.min({}): {}\".format(nameValue, np.max(value), nameValue, np.min(value)))\n",
    "        #print(\"{}.dtype: {} {}.shape: {}\".format(nameValue, value.dtype, nameValue, value.shape))\n",
    "    \n",
    "        value[np.isnan(value)] = 0 # Change all nan to 0\n",
    "\n",
    "        value[np.isneginf(value)] = 0 # Change all inf to 0\n",
    "        value[np.isposinf(value)] = 0 # Change all inf to 0\n",
    "        #value[np.isinf(value)] = 1 # Change all inf to 01\n",
    "\n",
    "        print(\"np.max({}): {} np.min({}): {}\".format(nameValue, np.max(value), nameValue, np.min(value)))\n",
    "\n",
    "#     if np.isnan(np.min(value)) or np.isnan(np.max(value)):\n",
    "#         print(\"np.isnan(np.min(\",nameValue,\"))!\")\n",
    "#         raise Exception(\"np.isnan(np.min(\",nameValue,\"))!\")\n",
    "\n",
    "#     if np.isinf(np.max(value)) or np.isinf(np.min(value)):\n",
    "#         print(\"np.isinf(np.max(\",nameValue,\"))!\")\n",
    "#         raise Exception(\"np.isnan(np.min(\",nameValue,\"))!\")\n",
    "\n",
    "    return value\n",
    "\n",
    "def normalize_vi(value): # calculate IKAW\n",
    "    ## normalize\n",
    "# https://stackoverflow.com/questions/38376478/changing-the-scale-of-a-tensor-in-tensorflow/38377600#38377600\n",
    "\n",
    "    min_value = np.min(value)\n",
    "    max_value = np.max(value)\n",
    "    #epsilon = 1e-12\n",
    "\n",
    "    normalized_value = (value - min_value) / (max_value - min_value)\n",
    "\n",
    "    #normalized_value = (value - min_value) / max((max_value - min_value), epsilon)\n",
    "    #normalized_value = (value - min_value + epsilon) / max((max_value - min_value), 2 * epsilon)\n",
    "\n",
    "    return normalized_value\n",
    "\n",
    "def normalized_RGB(img): # return normalized values for each RGB channel\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    # 24 bits image, 8 bits for each color, has 255 (2^8) as max value\n",
    "    Rn = R/255.0\n",
    "    Gn = G/255.0\n",
    "    Bn = B/255.0\n",
    "\n",
    "    return Rn, Gn, Bn\n",
    "\n",
    "def chromatic_coordinates(img): # Return cromatic coordinates for each RGB channel\n",
    "    Rn, Gn, Bn = normalized_RGB(img)\n",
    "\n",
    "    ALLn = Rn + Gn + Bn\n",
    "\n",
    "    r = Rn / ALLn\n",
    "    g = Gn / ALLn\n",
    "    b = Bn / ALLn\n",
    "\n",
    "    return r, g, b\n",
    "\n",
    "def calc_VI_01_VARI(img): # calculate VARI\n",
    "    r, g, b = chromatic_coordinates(img)\n",
    "\n",
    "    ## RuntimeWarning: divide by zero encountered in true_divide\n",
    "    vi_01_vari = (g - r) / (g + r - b)\n",
    "\n",
    "    #vi_01_vari = check_value_inf_nan(\"vi_num_1_inside\", vi_01_vari)\n",
    "\n",
    "    return vi_01_vari\n",
    "\n",
    "def calc_VI_02_ExG(img): # calculate ExG\n",
    "    r, g, b = chromatic_coordinates(img)\n",
    "\n",
    "    vi_02_ExG = 2 * g - r - b\n",
    "    return vi_02_ExG\n",
    "\n",
    "def calc_VI_03_ExR(img): # calculate ExR\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    vi_03_ExR = (1.4 * R - G) / ( R + G + B)\n",
    "    return vi_03_ExR\n",
    "\n",
    "def calc_VI_04_ExB(img): # calculate ExB\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    vi_04_ExB = (1.4 * B - G) / ( R + G + B)\n",
    "    return vi_04_ExB\n",
    "\n",
    "def calc_VI_05_ExGR(img): # calculate ExGR\n",
    "    r, g, b = chromatic_coordinates(img)\n",
    "\n",
    "    vi_02_ExG = calc_VI_02_ExG(img)\n",
    "    vi_03_ExR = calc_VI_03_ExR(img)\n",
    "\n",
    "    vi_05_ExGR = vi_02_ExG - vi_03_ExR\n",
    "    return vi_05_ExGR\n",
    "\n",
    "def calc_VI_06_GRVi(img): # calculate GRVI\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    vi_06_GRVI = (G - R) / (G + R)\n",
    "    return vi_06_GRVI\n",
    "\n",
    "def calc_VI_07_MGRVI(img): # calculate MGRVI\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    vi_07_MGRVI = (G ** 2 - R ** 2) / (G ** 2 + R ** 2)\n",
    "    return vi_07_MGRVI\n",
    "\n",
    "def calc_VI_08_GLI(img): # calculate GLI\n",
    "    r, g, b = chromatic_coordinates(img)\n",
    "\n",
    "    vi_08_GLI = (2 * g - r - b) / (-r - b)\n",
    "    return vi_08_GLI\n",
    "\n",
    "def calc_VI_09_RGBVI(img): # calculate RGBVI\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    vi_09_RGBVI = (G ** 2 - B * R) / (G ** 2 + B * R)\n",
    "    return vi_09_RGBVI\n",
    "\n",
    "def calc_VI_10_IKAW(img): # calculate IKAW\n",
    "    R, G, B = split_RGB_channel(img)\n",
    "\n",
    "    vi_10_IKAW = (R - B) / (R + B)\n",
    "    return vi_10_IKAW\n",
    "\n",
    "def return_vi_by_number(img, vi_num):\n",
    "    # img must be 3 chanel in unit8, i.e., 0 - 255 values\n",
    "    vi = ''\n",
    "\n",
    "    if vi_num == 1:\n",
    "        vi = calc_VI_01_VARI(img)\n",
    "    elif vi_num == 2:\n",
    "        vi = calc_VI_02_ExG(img)\n",
    "    elif vi_num == 3:\n",
    "        vi = calc_VI_03_ExR(img)\n",
    "    elif vi_num == 4:\n",
    "        vi = calc_VI_04_ExB(img)\n",
    "    elif vi_num == 5:\n",
    "        vi = calc_VI_05_ExGR(img)\n",
    "    elif vi_num == 6:\n",
    "        vi = calc_VI_06_GRVi(img)\n",
    "    elif vi_num == 7:\n",
    "        vi = calc_VI_07_MGRVI(img)\n",
    "    elif vi_num == 8:\n",
    "        vi = calc_VI_08_GLI(img)\n",
    "    elif vi_num == 9:\n",
    "        vi = calc_VI_09_RGBVI(img)\n",
    "    elif vi_num == 10:\n",
    "        vi = calc_VI_10_IKAW(img)\n",
    "\n",
    "#     print(\"\\n\\nvi_num:\", vi_num)\n",
    "#     print(\"\\nnp.max(vi):\", np.max(vi), \"np.min(vi):\", np.min(vi))\n",
    "#     print(\"vi.dtype:\", vi.dtype, \"vi.shape:\", vi.shape)\n",
    "\n",
    "#     print(\"\\ncheck_value_inf_nan\")\n",
    "    vi = check_value_inf_nan(\"vi_num_\" + str(vi_num), vi)\n",
    "#     print(\"np.max(vi):\", np.max(vi), \"np.min(vi):\", np.min(vi))\n",
    "#     print(\"vi.dtype:\", vi.dtype, \"vi.shape:\", vi.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "#     print(\"\\nnormalize_vi\")\n",
    "    vi = normalize_vi(vi)\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "#     print(\"np.max(vi):\", np.max(vi), \"np.min(vi):\", np.min(vi))\n",
    "#     print(\"vi.dtype:\", vi.dtype, \"vi.shape:\", vi.shape)\n",
    "\n",
    "    return vi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T04:53:11.076592Z",
     "start_time": "2022-11-15T04:53:11.048667Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine_img_VIs(img, vi_config, use_RGB):\n",
    "    vi_used = vi_config[1]\n",
    "\n",
    "    #print(\"\\n\\nimg:\", img.shape)\n",
    "    img_back = img.copy()\n",
    "\n",
    "    img = img / float(255)\n",
    "    #img = np.array(img)\n",
    "\n",
    "    for i, vi_num in enumerate(vi_used):\n",
    "#        print(\"\\n\\nvi_names[vi_num - 1]:\", vi_names[vi_num - 1])\n",
    "        vi = return_vi_by_number(img_back, vi_num)\n",
    "\n",
    "        #print(\"\\nnp.max(vi):\", np.max(vi), \"np.min(vi):\", np.min(vi))\n",
    "        #print(\"vi.dtype:\", vi.dtype, \"vi.shape:\", vi.shape)\n",
    "\n",
    "        \n",
    "        if i == 0:\n",
    "            if use_RGB:\n",
    "                img_aux = np.dstack((img, vi))\n",
    "            else:\n",
    "                #print(\"vi.shape:\", vi.shape)\n",
    "                vi = np.expand_dims(vi, 0) # vi.shape: (256, 256) to (1, 256, 256)\n",
    "                img_aux = np.dstack((vi))\n",
    "\n",
    "                #print(\"vi.shape:\", vi.shape)\n",
    "                #print(\"img_aux.shape:\", img_aux.shape)\n",
    "    \n",
    "        else:\n",
    "            img_aux = np.dstack((img_aux, vi))\n",
    "\n",
    "        #print(\"\\nimg_back.shape:\", img_back.shape)\n",
    "        #print(\"img_aux.shape:\", img_aux.shape)\n",
    "\n",
    "    #print(\"img_aux.shape:\", img_aux.shape)\n",
    "    #print(\"\\nnp.max(img_aux):\", np.max(img_aux), \"np.min(img_aux):\", np.min(img_aux))\n",
    "    #print(\"img_aux.dtype:\", img_aux.dtype, \"img_aux.shape:\", img_aux.shape)\n",
    "    \n",
    "    return img_aux\n",
    "\n",
    "## test\n",
    "from os import path\n",
    "path_folder = \"/media/sda2/home/j/Downloads/0del/00/iv/Recortes/Base_A/\"\n",
    "\n",
    "if not path.exists(path_folder):\n",
    "    path_folder = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/\"\n",
    "\n",
    "imgLoad = path_folder + \"A_0002.png\"\n",
    "imgLoad = path_folder + \"A_0431.png\"\n",
    "\n",
    "print(\"imgLoad:\", imgLoad)\n",
    "img = cv2.imread(imgLoad)\n",
    "#plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#plt.show()\n",
    "\n",
    "use_vi = True\n",
    "VIs_to_use = [1]\n",
    "#VIs_to_use = [1. 2, 3]\n",
    "#VIs_to_use = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "use_RGB = False\n",
    "#use_RGB = True\n",
    "vi_config = (use_vi, VIs_to_use)\n",
    "\n",
    "img_vi = combine_img_VIs(img, vi_config, use_RGB)\n",
    "print(\"\\nimg_vi.shape:\", img_vi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:10.072579Z",
     "start_time": "2023-01-15T23:04:10.056622Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_imgs_names(path):\n",
    "    names = []\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    #imgCount = len(files)\n",
    "\n",
    "    print(\"\\npath:\", path, \" len(files):\", len(files))\n",
    "    for file in files:\n",
    "        names.append(file)\n",
    "\n",
    "    return names #, imgCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:13.504939Z",
     "start_time": "2023-01-15T23:04:13.496933Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def adjust_data(img_batch, mask_batch, vi_config, use_RGB):\n",
    "    #print(\"\\n\\nimg_batch.shape:\", img_batch.shape)\n",
    "    #print(\"mask_batch.shape:\", mask_batch.shape)\n",
    "\n",
    "    if vi_config[0]: # check if use VI\n",
    "        # first axis is zero, for adding images along it\n",
    "        # create a 4d np array to add the images (with IV) in first space imgs_vi[_]\n",
    "        if use_RGB:\n",
    "            imgs_vi = np.empty((0, 256, 256, len(vi_config[1]) + 3))\n",
    "        else:\n",
    "            imgs_vi = np.empty((0, 256, 256, len(vi_config[1])))\n",
    "\n",
    "        count_imgs = img_batch.shape[0] # count imgs, the batch_size\n",
    "        for i in range(count_imgs): # For each img create all IVs and add them together\n",
    "            img = img_batch[i]\n",
    "            #print(\"\\n--->i:\", i + 1, \"img.shape: \", img.shape)\n",
    "\n",
    "            img_tmp_vi = combine_img_VIs(img, vi_config, use_RGB)\n",
    "            #print(\"\\n1 adjust_data - img_tmp_vi.shape:\", img_tmp_vi.shape)\n",
    "\n",
    "            # add a new axis to each image and append them to result\n",
    "            # add the img (with the IVs) to the array using a \"newaxis\"\n",
    "            imgs_vi = np.append(imgs_vi, img_tmp_vi[np.newaxis, ...], axis=0)\n",
    "\n",
    "            #img2 = img.copy()\n",
    "            #img2 = img2.astype('uint8')\n",
    "            ##print(img2)\n",
    "            #plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "            #plt.show()\n",
    "            #input()\n",
    "\n",
    "        img_batch = imgs_vi.copy()\n",
    "        #print(\"\\nf adjust_data - img_batch.shape:\", img_batch.shape) # (256, 256, 4)\n",
    "\n",
    "    else: #not using VI, adjust img_batch\n",
    "        img_batch = img_batch / float(255)\n",
    "        #img_batch = np.array(img_batch)\n",
    "\n",
    "    # Adjust mask_batch\n",
    "    mask_batch = mask_batch / float(255)\n",
    "    #print(\"b mask_batch.shape:\", mask_batch.shape)\n",
    "    #mask_batch = np.expand_dims(mask_batch, 2)\n",
    "    #print(\"a mask_batch.shape:\", mask_batch.shape)\n",
    "    #print(\"img_batch.shape:\", img_batch.shape)\n",
    "    #mask_batch = np.array(mask_batch)\n",
    "\n",
    "    #if mode == 0:\n",
    "    #    img = np.expand_dims(img, 2)\n",
    "\n",
    "#<--------------------------------------------------------------\n",
    "#    mask_batch[mask_batch >= 0.5] = 1\n",
    "#    mask_batch[mask_batch < 0.5] = 0\n",
    "\n",
    "    ## VI may have negative values, so not set to uint8, stay in float32\n",
    "    #img_batch = img_batch.astype('uint8')\n",
    "#    mask_batch = mask_batch.astype('uint8')\n",
    "#<--------------------------------------------------------------\n",
    "\n",
    "    #print(\"\\n\\nnp.max(img_batch):\", np.max(img_batch), \"np.min(img_batch):\", np.min(img_batch))\n",
    "    #print(\"img_batch.dtype:\", img_batch.dtype)\n",
    "\n",
    "    #print(\"np.max(mask_batch):\", np.max(mask_batch), \"np.min(mask_batch):\", np.min(mask_batch))\n",
    "    #print(\"mask_batch.dtype:\", mask_batch.dtype)\n",
    "\n",
    "    return img_batch, mask_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# make_generator_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:18.314066Z",
     "start_time": "2023-01-15T23:04:18.297138Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_generator_2(data_frame, batch_size, folder_path, img_folder, mask_folder, type_make, use_RGB):\n",
    "    count_img = len(data_frame)\n",
    "    print(\"\\nmake_generator2 Found\", count_img, \"image filenames - type_make:\", type_make)\n",
    "\n",
    "    i = 0\n",
    "    next_i_value = False\n",
    "    #while i <= count_img:\n",
    "    while True:\n",
    "        if i == count_img: # restart i to next epoch\n",
    "            #print(\"\\nNew epoch - type_make:\", type_make, \"\\n\")\n",
    "            i = 0\n",
    "\n",
    "        if next_i_value:\n",
    "            i = j\n",
    "            next_i_value = False\n",
    "\n",
    "        #imgs_vi = np.empty((0, 256, 256, len(vi_config[1]) + 3))\n",
    "        img_batch = np.empty((0, 256, 256, 3))\n",
    "        mask_batch = np.empty((0, 256, 256, 1))\n",
    "\n",
    "        j = i\n",
    "        next_step = i + batch_size\n",
    "        #print(\"j\", j, \"next_step\", next_step)\n",
    "        #print(\"\\n\\ndata_frame\", data_frame[i:i + batch_size], \"\\n\")\n",
    "\n",
    "        count_batch = 0\n",
    "        while count_batch < batch_size:\n",
    "            count_batch += 1\n",
    "\n",
    "            if j == count_img:\n",
    "                #print(\"---j == count_img---type_make:\", type_make)\n",
    "                j = 0\n",
    "                next_i_value = True\n",
    "\n",
    "            #file_name = \"/\" + data_frame.loc[j,:][0]\n",
    "            file_name = \"/\" + data_frame.loc[j][0]\n",
    "            #print(\"file_name:\", file_name)\n",
    "\n",
    "            img_name = folder_path + img_folder + file_name\n",
    "            #print(\"img_name:\", img_name)\n",
    "            mask_name = folder_path + mask_folder + file_name\n",
    "            #print(\"mask_name:\", mask_name)\n",
    "\n",
    "            img = cv2.imread(img_name, 1) # Read as RGB\n",
    "            mask = cv2.imread(mask_name, 0) # Read as grayscale\n",
    "\n",
    "            # expand_dims 256 x 256 to 256x256x1\n",
    "            mask = np.expand_dims(mask, 2)\n",
    "\n",
    "            #print(\"img.shape:\", img.shape)\n",
    "            #print(\"mask.shape:\", mask.shape)\n",
    "\n",
    "            img_batch = np.append(img_batch, img[np.newaxis, ...], axis=0) #img_batch[j] = img\n",
    "            mask_batch = np.append(mask_batch, mask[np.newaxis, ...], axis=0) #mask_batch[j] = mask\n",
    "\n",
    "            j += 1\n",
    "\n",
    "            #print(\"img[100,100]\", img[100,100])\n",
    "            #imsave(\"img2.png\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "            #imsave(\"mask.png\", mask, check_contrast=False)\n",
    "            #input()\n",
    "\n",
    "        i += batch_size\n",
    "\n",
    "#        print(\"before adjust_data img_batch.shape:\", img_batch.shape)\n",
    "#        print(\"before adjust_data mask_batch.shape:\", mask_batch.shape)\n",
    "\n",
    "        img_batch, mask_batch = adjust_data(img_batch, mask_batch, vi_config, use_RGB)\n",
    "\n",
    "#        print(\"after adjust_data img_batch.shape:\", img_batch.shape)\n",
    "#        print(\"after adjust_data mask_batch.shape:\", mask_batch.shape)\n",
    "\n",
    "        yield(img_batch, mask_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:20.846871Z",
     "start_time": "2023-01-15T23:04:20.832880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#f = [16, 32, 64, 128, 256] # Test 01\n",
    "#f = [16, 32, 64, 128] # Test 02\n",
    "#f = [16, 32, 64] # Test 03\n",
    "#f = [16, 32] # Test 04\n",
    "#f = [16] # Test 05\n",
    "#f = [16, 16] # Test 06\n",
    "#f = [16, 16, 16] # Test 07\n",
    "#f = [16, 16, 16, 16] # Test 08\n",
    "#f = [16, 16, 16, 16, 16] # Test 09\n",
    "#f = [32] # Test 10\n",
    "#f = [64] # Test 11\n",
    "#f = [128] # Test 12\n",
    "\n",
    "#----------\n",
    "\n",
    "#base_train = 'E'\n",
    "#base_output_path = '.\\\\Teste_09' + basebase_train_treino\n",
    "\n",
    "#path_carregar_pesos = ''\n",
    "#path_carregar_pesos = base_output_path + '/result.h5'\n",
    "\n",
    "#base_output_path = 'Teste_12' + base_train\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "kernel_size = (3, 3) #(3, 3)\n",
    "padding = \"same\" #\"same\"\n",
    "strides = 1 #1\n",
    "image_size = 256 #256\n",
    "epochs = 50 #50\n",
    "#epochs = 5 #50\n",
    "#epochs = 1 #50\n",
    "validation_split = 0.2 #0.2\n",
    "\n",
    "# batch_size = 8 # ResourceExhaustedError: Graph execution error,\n",
    "# Reduce your Dimension because of the limited RAM on GPU\n",
    "batch_size = 8 # 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:23.599751Z",
     "start_time": "2023-01-15T23:04:23.589791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "data_gen_args = dict(rotation_range=180,\n",
    "                    width_shift_range=0.07,\n",
    "                    height_shift_range=0.07,\n",
    "                    shear_range=0.07,\n",
    "                    zoom_range=0.07,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "#data_gen_args = dict() #<----\n",
    "\n",
    "#use_data_gen_args = True # True - Use data_gen_args\n",
    "use_data_gen_args = False # False - Don't use data_gen_args\n",
    "\n",
    "shuffleData = False # whether to shuffle the data (default: True)\n",
    "\n",
    "#save_trans_path = \"transformation\" #save_to_dir = None\n",
    "save_trans_path = None\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "seed = 42 # 0.93\n",
    "#seed = 1 # 0.9445\n",
    "#seed = 9\n",
    "\n",
    "save_predict = True\n",
    "#save_predict = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:26.393993Z",
     "start_time": "2023-01-15T23:04:26.377038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_dirs(output_dir):\n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"\\nCreated the directory:\", output_dir)\n",
    "\n",
    "# detect the current working directory and print it\n",
    "path = os.getcwd()\n",
    "print (\"Current working directory:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T23:04:29.103912Z",
     "start_time": "2023-01-15T23:04:29.085961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://faroit.com/keras-docs/2.0.2/metrics/\n",
    "# https://stackoverflow.com/questions/59054564/dice-coefficient-above-1\n",
    "# https://github.com/keras-team/keras/issues/3611\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# def dice_coef_loss(y_true, y_pred):\n",
    "#     #return - dice_coef(y_true, y_pred)\n",
    "#     return 1 - dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T08:59:01.141901Z",
     "start_time": "2023-01-16T08:50:18.768528Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 01 VARI  Visible Atmospherically Resistant Index\n",
    "# 02 ExG   Excess Green Index\n",
    "# 03 ExR   Excess Red Vegetation Index\n",
    "# 04 ExB   Excess Blue Vegetation Index\n",
    "# 05 EXGR  Excess Green minus Excess Red\n",
    "# 06 GRVI  Green Red Vegetation Index\n",
    "# 07 MGRVI Modified Green Red Vegetation Index\n",
    "# 08 GLI   Green Leaf Index\n",
    "# 09 RGBVI Red Green Blue Vegetation Index\n",
    "# 10 IKAW  Kawashima Index\n",
    "\n",
    "#path = \"/media/sda2/home/j/Downloads/0del/00/iv/Recortes/\"\n",
    "path = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/\"\n",
    "\n",
    "#letras_train = 'ABCDE'\n",
    "#letras_train = 'A'\n",
    "#letras_train = 'B'\n",
    "letras_train = 'E'\n",
    "#letras_train = 'L'\n",
    "\n",
    "#test = 1 #f = [16, 32, 64, 128, 256] # Test 01\n",
    "test = 9 #f = [16, 16, 16, 16, 16] # Test 09\n",
    "#test = 13 #f = [16, 16, 16, 16, 16, 16] # Test 13\n",
    "#test = 14 #f = [16, 16, 16, 16, 16, 16] # Test 14\n",
    "#test = 15 #f = [16, 16, 16, 16, 16, 16, 16] # Test 15\n",
    "#test = 16 #f = [16, 32, 64, 128, 256, 512] # Test 16\n",
    "\n",
    "train_model = True\n",
    "#train_model = False # Make predict\n",
    "\n",
    "use_vi = False #<--------------------------------\n",
    "#use_vi = True #<--------------------------------\n",
    "\n",
    "use_RGB = True # Use RGB channels\n",
    "#use_RGB = False\n",
    "\n",
    "# 1 - loss nan - need remove inf and nan\n",
    "# 2 to 10 ok\n",
    "\n",
    "VIs = [1]\n",
    "#VIs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "metrics_use = \"acc\"\n",
    "#metrics_use = \"dice_coef\"\n",
    "\n",
    "if not use_vi:\n",
    "    VIs = [1]\n",
    "    use_RGB = True\n",
    "print(\"\\nVIs:\", VIs)\n",
    "\n",
    "# <-------------------------------------------------------\n",
    "for v in VIs:\n",
    "    VIs_to_use = [v]\n",
    "\n",
    "# <-------------------------------------------------------    \n",
    "# run_value = [\n",
    "#         [1, 2, 3, 4, 5],\n",
    "#         [5, 6, 7, 8, 9, 10],\n",
    "#         [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "#     ]\n",
    "\n",
    "# for v in run_value:\n",
    "#     print(\"v:\", v)\n",
    "#     VIs_to_use = v\n",
    "\n",
    "# <-------------------------------------------------------\n",
    "\n",
    "    print(\"\\nVI normalized\")\n",
    "    #print(\"\\nVI NOT normalized\")\n",
    "\n",
    "    vi_config = (use_vi, VIs_to_use)\n",
    "    if vi_config[0]:\n",
    "        print(\"\\nUsing VI - vi_config[0]:\", vi_config[0])\n",
    "        #print(type(vi_config[1]))\n",
    "\n",
    "        if use_RGB:\n",
    "            img_channels = 3 + len(vi_config[1]) # Count of channel in the img: RGB + VIs\n",
    "        else:\n",
    "            img_channels = len(vi_config[1]) # Count of channel in the img: VIs\n",
    "\n",
    "        print(\"\\nVI in use:\", vi_config[1])\n",
    "        list_VIs = ''\n",
    "        for val in vi_config[1]:\n",
    "            print(vi_names[val - 1])\n",
    "            list_VIs += \"_\" + vi_names[val - 1][0]\n",
    "\n",
    "        print(\"\\nlist_VIs:\", list_VIs)\n",
    "    else:\n",
    "        print(\"\\nNot using VI - vi_config[0]:\", vi_config[0])\n",
    "        img_channels = 3 # Count of channel in the img and input U-Net model\n",
    "    print(\"\\nimg_channels:\", img_channels)\n",
    "\n",
    "    for base_train in letras_train:\n",
    "        dataset_img_folder = \"Base_\" + base_train\n",
    "        dataset_mask_folder = dataset_img_folder + \"_mask\"\n",
    "        print(\"\\ndataset_img_folder:\", dataset_img_folder)\n",
    "\n",
    "        if test == 1:\n",
    "            f = [16, 32, 64, 128, 256] # Test 01\n",
    "        elif test == 9:\n",
    "            f = [16, 16, 16, 16, 16] # Test 09\n",
    "        elif test == 13:\n",
    "            f = [16, 16, 16, 16, 16, 16] # Test 13\n",
    "        elif test == 14:\n",
    "            f = [16, 16, 16, 16, 16, 16, 16] # Test 14\n",
    "        elif test == 15:\n",
    "            f = [16, 16, 16, 16, 16, 16, 16, 16] # Test 15\n",
    "        elif test == 16:\n",
    "            f = [16, 32, 64, 128, 256, 512] # Test 16\n",
    "        else:\n",
    "            raise Exception(\"Test: \" + str(f) + \"- f not configured!\")\n",
    "\n",
    "        if use_RGB and img_channels == 3:\n",
    "            base_output_path = \"results/test_\" + str(test) + \"_U-Net_without_VI_weights_Base_\" + base_train\n",
    "        else: # img_channels >= 4\n",
    "            base_output_path = \"results/test_\" + str(test) + \"_U-Net_VI\" + list_VIs + \"_weights_Base_\" + base_train\n",
    "\n",
    "        print(\"\\nConfig:\", base_output_path)\n",
    "        print(\"test:\", test, \"f:\", f)\n",
    "        print(\"use_RGB:\", use_RGB)\n",
    "        #print(\"Configurações carregadas\")\n",
    "\n",
    "        #=======================================================================\n",
    "        inputs = keras.layers.Input((image_size, image_size, img_channels)) # img_channels => 3\n",
    "        p0 = inputs\n",
    "        down_blocks_layers = [{\n",
    "            \"p\": p0\n",
    "        }]\n",
    "        for i in range(len(f) - 1):\n",
    "            c, p = down_block(down_blocks_layers[i][\"p\"], f[i])\n",
    "            down_blocks_layers.append({\n",
    "                \"c\": c,\n",
    "                \"p\": p\n",
    "            })\n",
    "\n",
    "        bn = bottleneck(down_blocks_layers[len(down_blocks_layers)-1][\"p\"], f[len(f)-1])\n",
    "        up_blocks_layers = [bn]\n",
    "\n",
    "        for i in range(len(f) - 1):\n",
    "            invertI = len(f) - i - 1\n",
    "            p = up_block(up_blocks_layers[i],down_blocks_layers[invertI][\"c\"], f[invertI])\n",
    "            up_blocks_layers.append(p)\n",
    "\n",
    "        outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(up_blocks_layers[len(up_blocks_layers) - 1])\n",
    "        model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "        ##model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "\n",
    "        if metrics_use == \"acc\":\n",
    "            print(\"metrics=[\\\"acc\\\"]\")\n",
    "            model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "        elif metrics_use == \"dice_coef\":\n",
    "            print(\"metrics=[dice_coef]\")\n",
    "            model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[dice_coef])\n",
    "\n",
    "            #model.compile(optimizer=\"adam\", loss=dice_coef_loss, metrics=[dice_coef, \"acc\"])\n",
    "\n",
    "        model.summary()\n",
    "        print(\"Modelo criado!\")\n",
    "        #=======================================================================\n",
    "\n",
    "        if train_model:\n",
    "            path_carregar_pesos = ''\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "            # --- JB 1\n",
    "            #names, imgCount = load_imgs_names(path + 'Base_' + base_train + '/')\n",
    "            names = load_imgs_names(path + 'Base_' + base_train + '/')\n",
    "\n",
    "            train_index, test_index = train_test_split(names, test_size = validation_split,\n",
    "                                                       shuffle = True, random_state = seed)\n",
    "\n",
    "            train_data_frame = pd.DataFrame(train_index, columns = ['filename'])\n",
    "            test_data_frame = pd.DataFrame(test_index, columns = ['filename'])\n",
    "\n",
    "            print(\"\\nshuffle the data inside make_generator:\", shuffleData)\n",
    "\n",
    "            print(\"\\ntrain_data_frame\\n\", train_data_frame, \"\\n\\ntest_data_frame\\n\", test_data_frame)\n",
    "\n",
    "#             print(\"\\nmake_generator: make_generator\")\n",
    "#             train_generator = make_generator(train_data_frame, batch_size, path, dataset_img_folder,\n",
    "#                         dataset_mask_folder, aug_dict = data_gen_args, image_color_mode = \"rgb\",\n",
    "#                         save_to_dir = save_trans_path, target_size = (image_size, image_size),\n",
    "#                         seed = seed, use_data_gen_args = use_data_gen_args, shuffle = shuffleData, use_RGB = use_RGB)\n",
    "\n",
    "#             test_generator = make_generator(test_data_frame, batch_size, path, dataset_img_folder,\n",
    "#                         dataset_mask_folder, aug_dict = '', image_color_mode = \"rgb\",\n",
    "#                        save_to_dir = save_trans_path, target_size = (image_size, image_size),\n",
    "#                        seed = seed, use_data_gen_args = False, shuffle = shuffleData, use_RGB = use_RGB)\n",
    "\n",
    "            print(\"\\nmake_generator: make_generator_2\")\n",
    "            train_generator = make_generator_2(train_data_frame, batch_size, path, dataset_img_folder,\n",
    "                                               dataset_mask_folder, \"train\", use_RGB)\n",
    "\n",
    "            test_generator = make_generator_2(test_data_frame, batch_size, path, dataset_img_folder,\n",
    "                                              dataset_mask_folder, \"test\", use_RGB)\n",
    "\n",
    "            train_samples = len(train_index)\n",
    "            test_samples = len(test_index)\n",
    "            steps_p_epoch = int(train_samples / batch_size)\n",
    "            val_steps = int(test_samples / batch_size)\n",
    "\n",
    "            print(\" len(train_index):\", len(train_index), \"len(test_index):\", len(test_index))\n",
    "\n",
    "            print(\"\\ndataset_img_folder:\", dataset_img_folder) \n",
    "            print(\"batch_size:\", batch_size)\n",
    "            print(\"train_samples:\", train_samples)\n",
    "            print(\"test_samples:\", test_samples)\n",
    "            print(\"steps_p_epoch:\", steps_p_epoch)\n",
    "            print(\"val_steps:\", val_steps)\n",
    "            print(\"validation_split:\", validation_split)\n",
    "            print(\"use_data_gen_args:\", use_data_gen_args)\n",
    "            print()\n",
    "\n",
    "            #raise Exception(\"Error - loadImgsNames:\")\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "            # --- Backes\n",
    "            #trainImgs, nomes = loadImgs([path + 'Base_' + base_train + '/'], 1, img_channels)\n",
    "            #validImgs, nomes = loadImgs([path + 'Base_' + base_train + '_mask/'], 0, img_channels)\n",
    "\n",
    "            # --- JB 2\n",
    "#             trainImgs = loadImgs_new([path + 'Base_' + base_train + '/'], 1)\n",
    "#             validImgs = loadImgs_new([path + 'Base_' + base_train + '_mask/'], 0)\n",
    "\n",
    "#             print(\"\\nnp.max(trainImgs):\", np.max(trainImgs), \"np.min(trainImgs):\", np.min(trainImgs))\n",
    "#             print(\"trainImgs.dtype:\", trainImgs.dtype, \"trainImgs.shape:\", trainImgs.shape)\n",
    "\n",
    "            #print(\"Imagens carregadas\")\n",
    "\n",
    "            #=======================================================================\n",
    "            #plot_imgs(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=10, figsize=6)\n",
    "\n",
    "            #=======================================================================\n",
    "            #if(path_carregar_pesos == ''):\n",
    "\n",
    "            # model.fit verbose, verbose = 0 will show you nothing (silent)\n",
    "            # verbose=1 will show you an animated progress bar\n",
    "            # verbose=2 will just mention the number of epoch\n",
    "\n",
    "            # --- Backes and JB 2\n",
    "#             history = model.fit(trainImgs, validImgs, epochs = epochs, batch_size = batch_size,\n",
    "#                                 validation_split = validation_split, verbose = 1)\n",
    "\n",
    "            # --- JB 1\n",
    "            history = model.fit(train_generator, validation_data = test_generator, validation_steps = val_steps,\n",
    "                                steps_per_epoch = steps_p_epoch, epochs = epochs)\n",
    "\n",
    "            print('\\nModelo treinado')\n",
    "        else:\n",
    "            path_carregar_pesos = base_output_path + '/result.h5'\n",
    "            print(\"\\npath_carregar_pesos:\", path_carregar_pesos)\n",
    "\n",
    "            model.load_weights(path_carregar_pesos)\n",
    "            print('\\nPesos carregados')\n",
    "\n",
    "            history = '' # To not make error \"history not defined\"\n",
    "\n",
    "        #=======================================================================\n",
    "\n",
    "        modelSaver = ModelSaver(history, base_output_path)\n",
    "        print('\\nModelSaver criado!')\n",
    "\n",
    "        print(\"base_output_path:\", base_output_path)\n",
    "\n",
    "        #=======================================================================\n",
    "        if train_model:\n",
    "            if metrics_use == \"acc\":\n",
    "                print(\"metrics=[\\\"acc\\\"]\")\n",
    "                modelSaver.plotAndSaveMetrics(\"acc\", True)\n",
    "            elif metrics_use == \"dice_coef\":\n",
    "                print(\"metrics=[dice_coef]\")\n",
    "                modelSaver.plotAndSaveMetrics(\"dice_coef\", True) #<-----------------\n",
    "\n",
    "            #modelSaver.plotAndSaveMetrics(\"dice_coef_loss\", True)\n",
    "\n",
    "            #modelSaver.plotAndSaveMetrics(\"mean_io_u\", True) #<-----------------\n",
    "            modelSaver.plotAndSaveLoss(True)\n",
    "\n",
    "            modelSaver.saveModel(model)\n",
    "            modelSaver.saveHistory()\n",
    "\n",
    "        #=======================================================================\n",
    "        else:\n",
    "            #letras_predict=\"A\"\n",
    "            #letras_predict=\"ABCDE\"\n",
    "            #letras_predict=\"L\"\n",
    "            letras_predict=\"ABCDEL\"\n",
    "\n",
    "            for base_predict in letras_predict:\n",
    "                print(\"\\n\\nPredict of Base\", base_predict, \"with weights of Base\", base_train)\n",
    "\n",
    "                nr_files = len(glob.glob(path + \"Base_\" + base_predict + \"/*.png\"))\n",
    "                print(\"nr_files:\", nr_files)\n",
    "\n",
    "                output_dir = base_output_path + \"/result_images/predict_Base_\" + base_predict\n",
    "                print(\"\\noutput_dir:\", output_dir)\n",
    "\n",
    "                make_dirs(output_dir)\n",
    "\n",
    "                i = 1\n",
    "                for name in sorted(glob.glob(path + \"Base_\" + base_predict + \"/*.png\")):\n",
    "                    #print(\"name:\", name)\n",
    "\n",
    "                    img = cv2.imread(name)\n",
    "                    #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                    #plt.show()\n",
    "\n",
    "                    #print(\"\\nimg:\", img)\n",
    "\n",
    "                    #img_batch = img\n",
    "                    #mask_batch = img.copy()\n",
    "                    if vi_config[0]:\n",
    "                        img_tmp = combine_img_VIs(img, vi_config, use_RGB)\n",
    "                    else: #not using VI, adjust img_batch\n",
    "                        img_tmp = img / float(255)\n",
    "                        #img_tmp = np.array(img_tmp)\n",
    "\n",
    "                    ##img_tmp = adjust_data(img_batch, mask_batch, vi_config)\n",
    "\n",
    "                    #print(\"\\nimg_tmp:\", img_tmp)\n",
    "                    #print(\"\\nimg.shape:\", img.shape)\n",
    "                    #print(\"img_tmp.shape:\", img_tmp.shape)\n",
    "\n",
    "                    #imgs_vi = np.empty((0, 256, 256, len(vi_config[1]) + 3))\n",
    "                    #imgs_vi = np.append(imgs_vi, img_tmp[np.newaxis, ...], axis=0)\n",
    "                    #imgs_vi = np.append(imgs_vi, img_tmp[np.newaxis, ...], axis=0)\n",
    "\n",
    "                    pr = model.predict(np.array([img_tmp]))[0]\n",
    "                    #pr = model.predict(np.array([img_tmp]))\n",
    "\n",
    "                    #print(\"pr.shape:\", pr.shape)\n",
    "                    #print(\"pr.dtype:\", pr.dtype)\n",
    "                    #print(\"\\npr\", pr)\n",
    "\n",
    "                    #plt.imshow(pr * 255.0)\n",
    "                    #plt.imshow(pr)\n",
    "                    #plt.show()\n",
    "\n",
    "    # <----------------------------------------------------------------------\n",
    "                    #pr = np.array(pr)\n",
    "                    #pr = pr[:,:, 0]\n",
    "                    #pr[pr >= 0.5] = 1\n",
    "                    #pr[pr < 1] = 0\n",
    "                    #pr = pr * 255\n",
    "                    #pr = pr.astype('uint8')\n",
    "    # <----------------------------------------------------------------------\n",
    "\n",
    "                    #print(\"\\npr.shape:\", pr.shape)\n",
    "                    #print(\"pr.dtype:\", pr.dtype)\n",
    "                    #print(\"\\npr\", pr)\n",
    "\n",
    "                    if save_predict :\n",
    "                        name = name.replace(\"\\\\\",\"/\") # change \"\\\" to \"/\"\n",
    "                        name = name.split('/')[-1]\n",
    "                        #print(\"name:\", name)\n",
    "\n",
    "                        name_predict = output_dir + \"/\" + name\n",
    "                        #print(\"name_predict:\", name_predict)\n",
    "\n",
    "                        #imsave(name_predict, pr, check_contrast = False)\n",
    "                        #print(\"writing img:\",i,\" to\", output_path)\n",
    "\n",
    "                        cv2.imwrite(name_predict, pr * 255.0)\n",
    "                        #cv2.imwrite(name_predict, pr)\n",
    "\n",
    "                    #plt.imshow(pr * 255.0)\n",
    "                    #plt.show()\n",
    "                    #input()\n",
    "\n",
    "                    #avaliaImgs,avaliaImgsNomes = loadImgs([path + \"/Base_\"+ base_predict + '/'], 1, img_channels, vi_num)\n",
    "                    #print(\"\\nCount imagens:\", len(avaliaImgs))\n",
    "\n",
    "                    #modelSaver.predictAndSave(model, avaliaImgs, avaliaImgsNomes, 5)\n",
    "                    print(i, end=' ') # img print number running\n",
    "                    i += 1\n",
    "\n",
    "            print(\"\\n\\n# train_model is false, need just one to predict\")\n",
    "            break # train_model is false, need just one to predict\n",
    "\n",
    "print(\"\\n\\nAll Done!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T16:35:48.668101Z",
     "start_time": "2022-09-21T16:35:48.650545Z"
    },
    "hidden": true
   },
   "source": [
    "## End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## plot_VIs_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:00:23.483363Z",
     "start_time": "2022-09-24T23:00:21.231713Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_VIs_10(img, cmap=\"viridis\"): # default cmap=\"viridis\"\n",
    "    rows = 2\n",
    "    cols = 5\n",
    "\n",
    "    #fig, axes = plt.subplots(nm_img_to_plot, cols,\n",
    "    #     figsize = (cols * figsize, nm_img_to_plot * figsize), squeeze = False)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize = (15 * rows, 2.5 * cols))\n",
    "\n",
    "    vi_names = [\"01_VARI\", \"02_ExG\", \"03_ExR\", \"04_ExB\", \"05_EXGR\",\n",
    "               \"06_GRVI\", \"07_MGRVI\", \"08_GLI\", \"09_RGBVI\", \"10_IKAW\"]\n",
    "\n",
    "    posX = 0\n",
    "    posY = 0\n",
    "    for vi_num in range(1, 11):\n",
    "        #print (\"vi_num:\", vi_num)\n",
    "        print(vi_names[vi_num - 1])\n",
    "\n",
    "        vi = return_vi_by_number(img, vi_num)\n",
    "\n",
    "        print(\"np.max(vi):\", np.max(vi), \"np.min(vi):\", np.min(vi))\n",
    "        print(\"vi.dtype:\", vi.dtype, \"vi.shape:\", vi.shape)\n",
    "        \n",
    "        if np.isnan(np.amin(vi)):\n",
    "            print(\"Isnan\")\n",
    "            raise Exception(\"Isnan!\")\n",
    "\n",
    "        #print(\"axes[\",posX, posY,\"].\")\n",
    "        axes[posX, posY].set_title(vi_names[vi_num - 1], fontsize=15)\n",
    "\n",
    "        axes[posX, posY].set_axis_off()\n",
    "\n",
    "        #axes[posX, posY].imshow(vi)\n",
    "        axes[posX, posY].imshow(vi, cmap=cmap)\n",
    "\n",
    "        posY += 1\n",
    "        if posY == cols:\n",
    "            posY = 0\n",
    "            posX += 1\n",
    "\n",
    "    # set the spacing between subplots\n",
    "    #fig.tight_layout(pad=0, h_pad=None, w_pad=None, rect=None)\n",
    "    plt.show()\n",
    "\n",
    "## test\n",
    "#imgLoad = \"/media/sda2/home/j/Downloads/0del/00/iv/iv_pc_AB/Recortes/Base_A/A_0255.png\"\n",
    "imgLoad = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/A_0001.png\"\n",
    "\n",
    "img = cv2.imread(imgLoad)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "print(img)\n",
    "print(np.max(img))\n",
    "print(np.min(img))\n",
    "\n",
    "plot_VIs_10(img)\n",
    "\n",
    "plot_VIs_10(img, cmap = \"gray\")\n",
    "\n",
    "# https://docs.opencv.org/4.x/d3/d50/group__imgproc__colormap.html\n",
    "plot_VIs_10(img, cmap = \"hot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Old make_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T04:53:46.770330Z",
     "start_time": "2022-11-15T04:53:46.634412Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from skimage.io import imread, imsave\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#        train_generator = make_generator(train_data_frame, batch_size, path, dataset_img_folder,\n",
    "#                            dataset_mask_folder, aug_dict = data_gen_args, image_color_mode = \"rgb\",\n",
    "#                            save_to_dir = save_trans_path, target_size = (image_size, image_size),\n",
    "#                            seed = seed, use_data_gen_args = use_data_gen_args, shuffle = shuffleData)\n",
    "\n",
    "#        test_generator = make_generator(test_data_frame, batch_size, path, dataset_img_folder,\n",
    "#                            dataset_mask_folder, aug_dict = '', image_color_mode = \"rgb\",\n",
    "#                            save_to_dir = save_trans_path, target_size = (image_size, image_size),\n",
    "#                            seed = seed, use_data_gen_args = False, shuffle = shuffleData)\n",
    "\n",
    "def make_generator(data_frame, batch_size, folder_path, img_folder, mask_folder,\n",
    "                  aug_dict, image_color_mode = \"rgb\", mask_color_mode = \"grayscale\",\n",
    "                  image_save_prefix = \"image\", mask_save_prefix = \"mask\", flag_multi_class = False,\n",
    "                  num_class = 2, save_to_dir = None, target_size = (256, 256), seed = 42,\n",
    "                  use_data_gen_args = True, shuffle = False, use_RGB = True):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    If use_data_gen_args True will use aug_dict and make data aumentation\n",
    "    '''\n",
    "\n",
    "    #print(\"\\nfolder_path\", folder_path)\n",
    "    #!pwd\n",
    "    #!ls\n",
    "\n",
    "    if (use_data_gen_args):\n",
    "        image_datagen = ImageDataGenerator(**aug_dict)\n",
    "        mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    else:\n",
    "        image_datagen = ImageDataGenerator()\n",
    "        mask_datagen = ImageDataGenerator()\n",
    "\n",
    "        #image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        #mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    image_generator = image_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        folder_path + img_folder,\n",
    "        x_col = 'filename',\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix = image_save_prefix,\n",
    "        shuffle = shuffle,\n",
    "        seed = seed)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        folder_path + mask_folder,\n",
    "        x_col = 'filename',\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix = mask_save_prefix,\n",
    "        shuffle = shuffle,\n",
    "        seed = seed)\n",
    "\n",
    "    make_generator_info = zip(image_generator, mask_generator)\n",
    "\n",
    "    #count_img = len(data_frame)\n",
    "    #i = 0\n",
    "    for (img_batch, mask_batch) in make_generator_info:\n",
    "        #if i == count_img: # restart i to next epoch\n",
    "            #print(\"\\nNew epoch\\n\")\n",
    "            #i = 0\n",
    "\n",
    "        #img2 = img_batch[0, :, :, :]\n",
    "        #print(img2.shape)\n",
    "\n",
    "        #print (\"\\n\\ndata_frame\", data_frame[i:i + batch_size])\n",
    "        #i = i + batch_size\n",
    "    \n",
    "        #print(\"img_batch.shape\", img_batch.shape)\n",
    "\n",
    "        #mask2 = mask_batch[0, :, :, :]\n",
    "        #print(mask2.shape)\n",
    "\n",
    "        #imsave(\"img.png\", cv2.cvtColor(img2, cv2.COLOR_RGB2BGR))\n",
    "        #imsave(\"mask.png\", mask2)\n",
    "        #input()\n",
    "\n",
    "        img_batch, mask_batch = adjust_data(img_batch, mask_batch, vi_config, use_RGB)\n",
    "\n",
    "        yield(img_batch, mask_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## loadImgs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T05:53:23.659484Z",
     "start_time": "2022-10-23T05:53:23.648524Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#def loadImgs_new(path_list, mode, img_channels):\n",
    "def loadImgs_new(path_list, mode):\n",
    "    imgs = []\n",
    "    #nomes = []\n",
    "    for path in path_list:\n",
    "        files = os.listdir(path)\n",
    "        files.sort()\n",
    "        print(\"\\npath:\", path, \" len(files):\", len(files))\n",
    "        for file in files:\n",
    "            imgPath = os.path.join(path, file)\n",
    "\n",
    "            #print(\"loanding img:\",len(imgs), imgPath)\n",
    "            print(file, end = \" \")\n",
    "            img = cv2.imread(imgPath, mode) # 0 grayscale 1 to rgb\n",
    "\n",
    "            if mode == 0:\n",
    "                img = np.expand_dims(img, 2)\n",
    "                \n",
    "            if mode == 1:\n",
    "                if vi_config[0]:\n",
    "                    img = combine_img_VIs(img, vi_config)\n",
    "                else: #not using VI, adjust img_batch\n",
    "                    img = img / float(255)\n",
    "\n",
    "            imgs.append(img)\n",
    "            #nomes.append(file)\n",
    "\n",
    "    return np.array(imgs) #, nomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Others - tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T02:56:45.470110Z",
     "start_time": "2022-09-23T02:56:45.458140Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## print all ID - name of train_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:01:11.518341Z",
     "start_time": "2022-09-24T23:01:11.308513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i_index = 0\n",
    "for i in range(1, 201):\n",
    "    print(\"\\ni:\", i)\n",
    "    print(\"\\ni_index:\", i_index, \" to \", i_index + batch_size)\n",
    "    print (\"train_data_frame\", train_data_frame[i_index:i_index + batch_size])\n",
    "    i_index += batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Test numpy.ndarray nan and inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:01:56.502899Z",
     "start_time": "2022-09-24T23:01:56.471309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#imgLoad = \"/media/sda2/home/j/Downloads/0del/00/iv/iv_pc_AB/Recortes/Base_A/A_0431.png\"\n",
    "imgLoad = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A/A_0431.png\"\n",
    "\n",
    "img = cv2.imread(imgLoad)\n",
    "print(img.dtype)\n",
    "\n",
    "img = img.astype('float32')\n",
    "print(img.dtype)\n",
    "\n",
    "print(\"type(img):\", type(img))\n",
    "\n",
    "img[0,0,0] = 0.1\n",
    "print(\"\\n 0.1/0: \", (img[0,0,0]) / 0)\n",
    "\n",
    "img[0,0,0] = -0.1\n",
    "print(\"-0.1/0:\", (img[0,0,0]) / 0)\n",
    "\n",
    "img[0,0,0] = 0\n",
    "print(\" 0/0:   \", (img[0,0,0]) / 0)\n",
    "print(\" 0/0.1: \", (img[0,0,0]) / 0.1)\n",
    "\n",
    "# 0/0 = nan\n",
    "# >0/0 = inf, <0/0 = -inf\n",
    "# 0/1 = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## expand_dims np arry img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:02:31.001402Z",
     "start_time": "2022-09-24T23:02:30.904704Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#imgLoad = \"/media/sda2/home/j/Downloads/0del/00/iv/iv_pc_AB/Recortes/Base_A_mask/A_0001.png\"\n",
    "imgLoad = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/Base_A_mask/A_0001.png\"\n",
    "\n",
    "img = cv2.imread(imgLoad, 0)\n",
    "\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()\n",
    "\n",
    "print(\"img.shape:\", img.shape)\n",
    "\n",
    "img = img / 255.0\n",
    "img = np.array(img)\n",
    "print(\"img.shape:\", img.shape)\n",
    "\n",
    "img = np.expand_dims(img, 2)\n",
    "print(\"img.shape:\", img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Print all VI info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:02:34.627061Z",
     "start_time": "2022-09-24T23:02:34.616302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_vi = True\n",
    "vi_to_use = (1,2,3)\n",
    "\n",
    "vi_config = (use_vi, vi_to_use)\n",
    "\n",
    "vi_test = vi_config[0]\n",
    "vi_used = vi_config[1]\n",
    "\n",
    "print(\"Using VI:\", vi_config[0])\n",
    "if vi_config[0]:\n",
    "    print(\"VI in use:\", vi_config[1])\n",
    "    for val in vi_config[1]:\n",
    "        print(vi_names[val - 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Restarting kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-24T22:56:52.038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Restarting kernel\")\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:11:09.303803Z",
     "start_time": "2022-09-29T19:11:08.905194Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# list of variables\n",
    "%whos \n",
    "\n",
    "#del pr_Imgs\n",
    "\n",
    "#%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:02:50.702436Z",
     "start_time": "2022-09-24T23:02:50.663377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(dir())\n",
    "\n",
    "import sys\n",
    "\n",
    "#del trainImgs\n",
    "#del nomes\n",
    "#del validImgs\n",
    "#del avaliaImgs\n",
    "#sys.getsizeof(pd)\n",
    "\n",
    "for var in dir():\n",
    "    #print(var, type(eval(var)), eval(var), sys.getsizeof(eval(var)))\n",
    "    print(var, sys.getsizeof(eval(var)))\n",
    "    #del var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T23:02:45.274247Z",
     "start_time": "2022-09-24T23:02:45.242332Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = np.random.random((256, 256, len(vi_config[1]) + 3))\n",
    "print(img.shape)\n",
    "\n",
    "result = np.empty((0, 256, 256, len(vi_config[1]) + 3)) # First axis is zero, for adding images along it\n",
    "\n",
    "for i in range(5): # replace this loop with something that reads in the images\n",
    "    result = np.append(result, img[np.newaxis, ...], axis=0) # add a new axis to each image and append them to result\n",
    "\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "308px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "274.85px",
    "left": "814px",
    "right": "20px",
    "top": "115px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
