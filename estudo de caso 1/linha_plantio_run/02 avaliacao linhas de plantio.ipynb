{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm\n",
    "from segmentation_models.utils import set_trainable\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## error\n",
    "#from keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# AttributeError: module 'keras.utils' has no attribute 'get_file' using segmentation_models\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "## Using function in this notebook\n",
    "#from model import *\n",
    "#from data import *\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available\", len(physical_devices))\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To disable GPU and use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "#import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "# No GPU found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustData(img, mask, flag_multi_class, num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask >= 0.5] = 1\n",
    "        mask[mask < 0.5] = 0\n",
    "    return (img,mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=180,\n",
    "                    width_shift_range=0.07,\n",
    "                    height_shift_range=0.07,\n",
    "                    shear_range=0.07,\n",
    "                    zoom_range=0.07,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "## To check\n",
    "#batch_size = 2\n",
    "#train_samples = 330\n",
    "#test_samples = 37\n",
    "#steps_p_epoch = int(train_samples / batch_size)\n",
    "#val_steps = int(test_samples / batch_size)\n",
    "\n",
    "nr_epochs = 50 #50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skimage.io import imread, imsave\n",
    "\n",
    "def makeGenerator(data_frame, batch_size, folder_path, img_folder, mask_folder,\n",
    "                  aug_dict, image_color_mode = \"grayscale\",\n",
    "                  mask_color_mode = \"grayscale\", image_save_prefix = \"image\", mask_save_prefix = \"mask\",\n",
    "                  flag_multi_class = False, num_class = 2, save_to_dir = None, target_size = (256, 256),\n",
    "                  seed = 42, isTrainGenerator = True):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    If isTrainGenerator True will use aug_dict and make data aumentation\n",
    "    '''\n",
    "\n",
    "    #print(\"\\nfolder_path\", folder_path)\n",
    "    #!pwd\n",
    "    #!ls\n",
    "\n",
    "    if (isTrainGenerator):\n",
    "        image_datagen = ImageDataGenerator(**aug_dict)\n",
    "        mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    else:\n",
    "        image_datagen = ImageDataGenerator()\n",
    "        mask_datagen = ImageDataGenerator()\n",
    "\n",
    "    image_generator = image_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        folder_path + img_folder,\n",
    "        x_col = 'filename',\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix = image_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        folder_path + mask_folder,\n",
    "        x_col = 'filename',\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    make_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in make_generator:\n",
    "        #print(\"img, mask\")\n",
    "        #!dir\n",
    "\n",
    "        #print(\"img\", img)\n",
    "        #print(type(img))\n",
    "        #print(img.dtype)\n",
    "        #print(img.shape)\n",
    "        #print(mask.shape)\n",
    "\n",
    "        #img2 = img[0, :, :, :]\n",
    "        #print(img2.shape)\n",
    "\n",
    "        #mask2 = mask[0, :, :, :]\n",
    "        #print(mask2.shape)\n",
    "\n",
    "        #imsave(\"img.png\", img2, check_contrast=False)\n",
    "        #imsave(\"mask.png\", mask2, check_contrast=False)\n",
    "\n",
    "        img, mask = adjustData(img, mask, flag_multi_class, num_class)\n",
    "        yield(img, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_model(DECODER, BACKBONE, input_shape, encoder_weights, encoder_freeze, classes, activation):\n",
    "def load_model(DECODER, model_args):\n",
    "    #model = sm.Unet(\n",
    "    #model = sm.Linknet(\n",
    "    #model = sm.PSPNet(\n",
    "\n",
    "    #    backbone_name=BACKBONE, input_shape=(x, x, 3), encoder_weights='imagenet',\n",
    "    #    encoder_freeze=True, classes=1, activation='sigmoid'\n",
    "    #)\n",
    "\n",
    "    ## input_shape â€“ shape of input data/image (H, W, C)\n",
    "        # Unet and Linknet - H and W of input images should be divisible by factor 32.\n",
    "        # PSPNet - H and W should be divisible by 6 * downsample_factor and NOT None! - downsample_factor = 8\n",
    "\n",
    "    if DECODER == \"Unet\":\n",
    "        print(\"\\n1 DECODER:\", DECODER)\n",
    "        model = sm.Unet(**model_args)\n",
    "\n",
    "    elif DECODER == \"Linknet\":\n",
    "        print(\"\\n2 DECODER:\", DECODER)\n",
    "        model = sm.Linknet(**model_args)\n",
    "\n",
    "    elif DECODER == \"PSPNet\":\n",
    "        print(\"\\n3 DECODER:\", DECODER)\n",
    "        model = sm.PSPNet(**model_args)\n",
    "    else :\n",
    "        raise ValueError(\"Error DECODER:\", DECODER)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check\n",
    "\n",
    "## Seed in def makeGenerator() diff to train and test\n",
    "    ###Status = OK\n",
    "\n",
    "## Seed in def makeGenerator()\n",
    "    batch_size = 2\n",
    "    train_samples = len(train_index) # 330\n",
    "    test_samples = len(test_index) # 37 \n",
    "    steps_p_epoch = int(train_samples / batch_size)\n",
    "    val_steps = int(test_samples / batch_size)\n",
    "    ### Status = OK\n",
    "\n",
    "## Add fold in file name\n",
    "    ### Status = ok\n",
    "\n",
    "## Run code with GPU\n",
    "    ### Status = OK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Define model\n",
    "#DECODER = \"Unet\"\n",
    "#DECODER = \"Linknet\"\n",
    "#DECODER = \"PSPNet\"\n",
    "\n",
    "#path = \"/media/sda2/home/j/Downloads/tests/recortes_tmp/\"\n",
    "path = \"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/\"\n",
    "#path = \"/run/media/j/tmp_ntfs/0_t_mest_bkp/tests/Segmentacao Linha Plantio CNN/Recortes/\"\n",
    "\n",
    "#dataset_img_folder = \"Base_A\"\n",
    "#dataset_img_folder = \"Base_B\"\n",
    "#dataset_img_folder = \"Base_C\"\n",
    "#dataset_img_folder = \"Base_D\"\n",
    "\n",
    "#dataset_img_folder = \"Base_E200\"\n",
    "#dataset_img_folder = \"Base_E300\"\n",
    "#dataset_img_folder = \"Base_E400\"\n",
    "dataset_img_folder = \"Base_E500\"\n",
    "\n",
    "dataset_mask_folder = dataset_img_folder + \"_mask\"\n",
    "\n",
    "folds = 10\n",
    "\n",
    "resultFolder = \"results/\" + dataset_img_folder + '/'\n",
    "\n",
    "#save_trans_path = \"transformation\" #save_to_dir = None\n",
    "save_trans_path = None\n",
    "\n",
    "BACKBONE = \"vgg16\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for i in range(3): #3\n",
    "    if i == 0:\n",
    "        DECODER = \"Unet\"\n",
    "    elif i == 1:\n",
    "        DECODER = \"Linknet\"\n",
    "    elif i == 2:\n",
    "        DECODER = \"PSPNet\"\n",
    "\n",
    "    #files = sorted(glob.glob(os.path.join(path + dataset_img_folder, \"*.png\")))\n",
    "    files = sorted([os.path.basename(x) for x in glob.glob(os.path.join(path + dataset_img_folder, \"*.png\"))])\n",
    "    #for name in files:\n",
    "    #    print(name)\n",
    "\n",
    "    #The first n_samples % n_splits folds have size n_samples // n_splits + 1,\n",
    "    #other folds have size n_samples // n_splits, where n_samples is the number of samples\n",
    "    kf = KFold(n_splits = folds, random_state = 42, shuffle = True)\n",
    "\n",
    "    nr_fold = 1 #1\n",
    "    fold_to_jump = 0 #0\n",
    "\n",
    "    for train_index, test_index in kf.split(files):\n",
    "        #print(\"\\nTRAIN:\", train_index, \"\\n\\nTEST:\", test_index)\n",
    "        #X_train, X_test = X[train_index], X[test_index]\n",
    "        #y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        if (nr_fold <= fold_to_jump):\n",
    "            print(\"\\n\\nFold: - nothing to do\", nr_fold, end = '')\n",
    "            nr_fold = nr_fold + 1\n",
    "            continue\n",
    "\n",
    "        train_list_files = []\n",
    "        for it in train_index:\n",
    "            train_list_files.append(files[it])\n",
    "\n",
    "        test_list_files = []\n",
    "        for it in test_index:\n",
    "            test_list_files.append(files[it])\n",
    "\n",
    "        ## To check\n",
    "        batch_size = 2\n",
    "        train_samples = len(train_index)\n",
    "        test_samples = len(test_index)\n",
    "        steps_p_epoch = int(train_samples / batch_size)\n",
    "        val_steps = int(test_samples / batch_size)\n",
    "\n",
    "        print(\"\\nFold:\", nr_fold, end = '')\n",
    "        print(\" len(train_index):\", len(train_index), \"len(test_index):\", len(test_index))\n",
    "\n",
    "        print(\"\\ndataset_img_folder:\", dataset_img_folder) \n",
    "        print(\"batch_size:\", batch_size)\n",
    "        print(\"train_samples:\", train_samples)\n",
    "        print(\"test_samples:\", test_samples)\n",
    "        print(\"steps_p_epoch:\", steps_p_epoch)\n",
    "        print(\"val_steps:\", val_steps)\n",
    "\n",
    "        train_data_frame = pd.DataFrame(train_list_files, columns = ['filename'])\n",
    "        test_data_frame = pd.DataFrame(test_list_files, columns = ['filename'])\n",
    "        #print(\"\\ntrain_data_frame\\n\", train_data_frame, \"\\n\\ntest_data_frame\\n\", test_data_frame)\n",
    "\n",
    "        preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "        # size - target_size?: 240 PSPNet, 256 Unet and Linknet, 288 All\n",
    "        if DECODER == \"Unet\" or DECODER == \"Linknet\":\n",
    "            size = 256 # 240 # 256 # 288 ## target_size\n",
    "        elif DECODER == \"PSPNet\":\n",
    "            size = 240\n",
    "        else:\n",
    "            raise ValueError(\"Error DECODER:\", DECODER)\n",
    "\n",
    "        print(\"\\ntarget_size:\", size, size)\n",
    "\n",
    "        trainGene = makeGenerator(train_data_frame, batch_size, path, dataset_img_folder, dataset_mask_folder,\n",
    "                                  aug_dict = data_gen_args, save_to_dir = save_trans_path, image_color_mode = \"rgb\",\n",
    "                                  isTrainGenerator = True, target_size = (size, size))\n",
    "\n",
    "        testGene = makeGenerator(test_data_frame, batch_size, path, dataset_img_folder, dataset_mask_folder,\n",
    "                                 aug_dict = '', save_to_dir = save_trans_path, image_color_mode = \"rgb\",\n",
    "                                 isTrainGenerator = False, target_size = (size, size))\n",
    "\n",
    "        ## input_shape â€“ shape of input data/image (H, W, C)\n",
    "            # Unet and Linknet - H and W of input images should be divisible by factor 32.\n",
    "            # PSPNet - H and W should be divisible by 6 * downsample_factor and NOT None! - downsample_factor = 8\n",
    "\n",
    "        ## add input_shape = (size, size, 3) beacuse PSPNet\n",
    "        data_load_model_args = dict(backbone_name = BACKBONE, input_shape = (size, size, 3),\n",
    "                                    encoder_weights='imagenet', encoder_freeze = True,\n",
    "                                    classes = 1, activation = 'sigmoid')\n",
    "\n",
    "        model = load_model(DECODER, data_load_model_args)\n",
    "\n",
    "        if nr_fold == 1:\n",
    "            model.summary()\n",
    "\n",
    "        #model = sm.Unet(\n",
    "        #model = sm.Linknet(\n",
    "        #model = sm.PSPNet(\n",
    "        #model = sm.PSPNet(backbone_name=BACKBONE, input_shape=(240, 240, 3),\n",
    "        #model = sm.PSPNet(backbone_name=BACKBONE, input_shape=(288, 288, 3),\n",
    "\n",
    "        #model = sm.Unet(\n",
    "        #model = sm.Linknet(\n",
    "        #model = sm.PSPNet(\n",
    "            #backbone_name=BACKBONE, input_shape=(x, x, 3),\n",
    "            #encoder_weights='imagenet',\n",
    "            #encoder_freeze=True,\n",
    "            #classes=1,\n",
    "            #activation='sigmoid'\n",
    "        #)\n",
    "\n",
    "        opt = Adam(learning_rate = 1e-3)\n",
    "\n",
    "        model.compile(opt,\n",
    "            loss=sm.losses.jaccard_loss,\n",
    "            metrics=[sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), sm.metrics.precision]\n",
    "        )\n",
    "\n",
    "        csv_logger = CSVLogger(resultFolder + BACKBONE + \"_\" + DECODER  + \"_\" + dataset_img_folder + \".csv\", append=True)\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint(resultFolder + BACKBONE + \"_\" + DECODER + \"_\" + dataset_img_folder + \"_\" +\n",
    "                                           str(nr_fold) + \".hdf5\", monitor = \"loss\", verbose = 1, save_best_only=True)\n",
    "\n",
    "        history = model.fit_generator(generator = trainGene,\n",
    "            validation_data = testGene,\n",
    "            validation_steps = val_steps,\n",
    "            steps_per_epoch = steps_p_epoch,\n",
    "            epochs = nr_epochs,\n",
    "            callbacks = [model_checkpoint, csv_logger])\n",
    "\n",
    "        nr_fold = nr_fold + 1\n",
    "\n",
    "print(\"\\n\\nAll Done!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
