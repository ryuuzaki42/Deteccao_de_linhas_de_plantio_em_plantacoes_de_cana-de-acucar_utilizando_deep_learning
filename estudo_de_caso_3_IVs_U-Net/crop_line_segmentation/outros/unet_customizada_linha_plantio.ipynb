{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o exemplo abaixo:\n",
    "# https://github.com/karolzak/keras-unet/blob/master/notebooks/kz-whale-tails.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available\", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_size=(3, 3)\n",
    "padding=\"same\"\n",
    "strides=1\n",
    "image_size = 256\n",
    "epochs = 5 #50\n",
    "validation_split= 0.2\n",
    "batch_size=8\n",
    "\n",
    "#path_carregar_pesos = '.\\\\result_100epochs_256input_5filtros\\\\result.h5'\n",
    "path_carregar_pesos = ''\n",
    "\n",
    "#f = [16, 32, 64, 128, 256] # configuração original\n",
    "\n",
    "#f = [16, 32, 64, 128, 256] # Teste 01\n",
    "#f = [16, 32, 64, 128] # Teste 02\n",
    "#f = [16, 32, 64] # Teste 03\n",
    "#f = [16, 32] # Teste 04\n",
    "#f = [16] # Teste 05\n",
    "#f = [16, 16] # Teste 06\n",
    "#f = [16, 16, 16] # Teste 07\n",
    "#f = [16, 16, 16, 16] # Teste 08\n",
    "f = [16, 16, 16, 16, 16] # Teste 09\n",
    "#f = [32] # Teste 10\n",
    "#f = [64] # Teste 11\n",
    "#f = [128] # Teste 12\n",
    "\n",
    "base_treino = 'E'\n",
    "base_output_path = '.\\\\Teste_09' + base_treino\n",
    "\n",
    "print(\"Configurações carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "inputs = keras.layers.Input((image_size, image_size, 3))\n",
    "p0 = inputs\n",
    "down_blocks_layers = [{\n",
    "    \"p\": p0\n",
    "}]\n",
    "for i in range(len(f) -1 ):\n",
    "    c, p = down_block(down_blocks_layers[i][\"p\"], f[i])\n",
    "    down_blocks_layers.append({\n",
    "        \"c\": c,\n",
    "        \"p\": p\n",
    "    })\n",
    "    \n",
    "\n",
    "bn = bottleneck(down_blocks_layers[len(down_blocks_layers)-1][\"p\"], f[len(f)-1])\n",
    "up_blocks_layers = [bn]\n",
    "\n",
    "for i in range(len(f) -1 ):\n",
    "    invertI = len(f) - i  - 1\n",
    "    p = up_block(up_blocks_layers[i],down_blocks_layers[invertI][\"c\"], f[invertI])\n",
    "    up_blocks_layers.append(p)\n",
    "\n",
    "outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(up_blocks_layers[len(up_blocks_layers) - 1])\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "#model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "print(\"Modelo criado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loadImgs(path_list, mode):\n",
    "    imgs = []\n",
    "    nomes = []\n",
    "    for path in path_list:\n",
    "        files = os.listdir(path)\n",
    "        files.sort()\n",
    "        print(\"path:\", path, \" file\", len(files))\n",
    "        for file in files:\n",
    "            imgPath = os.path.join(path, file)\n",
    "            print(\"loanding img:\",len(imgs), imgPath)\n",
    "            img = cv2.imread(imgPath, mode)\n",
    "            if mode == 0:\n",
    "                 img = np.expand_dims(img, 2)\n",
    "            img = img / float(255)\n",
    "            imgs.append(img)\n",
    "            nomes.append(file)\n",
    "\n",
    "    return np.array(imgs),nomes\n",
    "\n",
    "# Load images\n",
    "# trainImgs,nomes = loadImgs(['./Recortes/Base_A/'], 1)\n",
    "# validImgs,nomes = loadImgs(['./Recortes/Base_A_mask/'], 0)\n",
    "\n",
    "imgPath=\"E:/Backes/Segmentacao Linha Plantio CNN/Recortes/\"\n",
    "\n",
    "trainImgs,nomes = loadImgs([imgPath + 'Base_'+base_treino+'/'], 1)\n",
    "validImgs,nomes = loadImgs([imgPath + 'Base_'+base_treino+'_mask/'], 0)\n",
    "\n",
    "print(\"Imagens carregadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_COLORS = [\n",
    "    \"red\", \"green\", \"blue\",\n",
    "    \"yellow\", \"magenta\", \"cyan\"\n",
    "]\n",
    "\n",
    "def mask_to_rgba(mask, color=\"red\"):\n",
    "    \"\"\"\n",
    "    Converts binary segmentation mask from white to red color.\n",
    "    Also adds alpha channel to make black background transparent.\n",
    "    \n",
    "    Args:\n",
    "        mask (numpy.ndarray): [description]\n",
    "        color (str, optional): Check `MASK_COLORS` for available colors. Defaults to \"red\".\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: [description]\n",
    "    \"\"\"    \n",
    "    assert(color in MASK_COLORS)\n",
    "    assert(mask.ndim==3 or mask.ndim==2)\n",
    "\n",
    "    h = mask.shape[0]\n",
    "    w = mask.shape[1]\n",
    "    zeros = np.zeros((h, w))\n",
    "    ones = mask.reshape(h, w)\n",
    "    if color == \"red\":\n",
    "        return np.stack((ones, zeros, zeros, ones), axis=-1)\n",
    "    elif color == \"green\":\n",
    "        return np.stack((zeros, ones, zeros, ones), axis=-1)\n",
    "    elif color == \"blue\":\n",
    "        return np.stack((zeros, zeros, ones, ones), axis=-1)\n",
    "    elif color == \"yellow\":\n",
    "        return np.stack((ones, ones, zeros, ones), axis=-1)\n",
    "    elif color == \"magenta\":\n",
    "        return np.stack((ones, zeros, ones, ones), axis=-1)\n",
    "    elif color == \"cyan\":\n",
    "        return np.stack((zeros, ones, ones, ones), axis=-1)\n",
    "    \n",
    "def get_cmap(arr):\n",
    "    \"\"\"[summary]\n",
    "    \n",
    "    Args:\n",
    "        arr (numpy.ndarray): [description]\n",
    "    \n",
    "    Returns:\n",
    "        string: [description]\n",
    "    \"\"\"\n",
    "    if arr.ndim == 3:\n",
    "        return \"gray\"\n",
    "    elif arr.ndim == 4:\n",
    "        if arr.shape[3] == 3:\n",
    "            return \"jet\"\n",
    "        elif arr.shape[3] == 1:\n",
    "            return \"gray\"\n",
    "\n",
    "def zero_pad_mask(mask, desired_size):\n",
    "    \"\"\"[summary]\n",
    "    \n",
    "    Args:\n",
    "        mask (numpy.ndarray): [description]\n",
    "        desired_size ([type]): [description]\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: [description]\n",
    "    \"\"\"\n",
    "    pad = (desired_size - mask.shape[0]) // 2\n",
    "    padded_mask = np.pad(mask, pad, mode=\"constant\")\n",
    "    return padded_mask\n",
    "\n",
    "def reshape_arr(arr):\n",
    "    \"\"\"[summary]\n",
    "    \n",
    "    Args:\n",
    "        arr (numpy.ndarray): [description]\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: [description]\n",
    "    \"\"\"\n",
    "    if arr.ndim == 3:\n",
    "        return arr\n",
    "    elif arr.ndim == 4:\n",
    "        if arr.shape[3] == 3:\n",
    "            return arr\n",
    "        elif arr.shape[3] == 1:\n",
    "            return arr.reshape(arr.shape[0], arr.shape[1], arr.shape[2])\n",
    "        \n",
    "def plot_imgs(\n",
    "        org_imgs,\n",
    "        mask_imgs,\n",
    "        pred_imgs=None,\n",
    "        nm_img_to_plot=10,\n",
    "        figsize=4,\n",
    "        alpha=0.5,\n",
    "        color=\"red\"):\n",
    "    \"\"\"\n",
    "    Image plotting for semantic segmentation data.\n",
    "    Last column is always an overlay of ground truth or prediction\n",
    "    depending on what was provided as arguments.\n",
    "    Args:\n",
    "        org_imgs (numpy.ndarray): Array of arrays representing a collection of original images.\n",
    "        mask_imgs (numpy.ndarray): Array of arrays representing a collection of mask images (grayscale).\n",
    "        pred_imgs (numpy.ndarray, optional): Array of arrays representing a collection of prediction masks images.. Defaults to None.\n",
    "        nm_img_to_plot (int, optional): How many images to display. Takes first N images. Defaults to 10.\n",
    "        figsize (int, optional): Matplotlib figsize. Defaults to 4.\n",
    "        alpha (float, optional): Transparency for mask overlay on original image. Defaults to 0.5.\n",
    "        color (str, optional): Color for mask overlay. Defaults to \"red\".\n",
    "    \"\"\" # NOQA E501\n",
    "    assert(color in MASK_COLORS)\n",
    "\n",
    "    if nm_img_to_plot > org_imgs.shape[0]:\n",
    "        nm_img_to_plot = org_imgs.shape[0]\n",
    "    im_id = 0\n",
    "    org_imgs_size = org_imgs.shape[1]\n",
    "\n",
    "    org_imgs = reshape_arr(org_imgs)\n",
    "    mask_imgs = reshape_arr(mask_imgs)\n",
    "    if not (pred_imgs is None):\n",
    "        cols = 4\n",
    "        pred_imgs = reshape_arr(pred_imgs)\n",
    "    else:\n",
    "        cols = 3\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nm_img_to_plot, cols, figsize=(cols * figsize, nm_img_to_plot * figsize), squeeze=False\n",
    "    )\n",
    "    axes[0, 0].set_title(\"original\", fontsize=15)\n",
    "    axes[0, 1].set_title(\"ground truth\", fontsize=15)\n",
    "    if not (pred_imgs is None):\n",
    "        axes[0, 2].set_title(\"prediction\", fontsize=15)\n",
    "        axes[0, 3].set_title(\"overlay\", fontsize=15)\n",
    "    else:\n",
    "        axes[0, 2].set_title(\"overlay\", fontsize=15)\n",
    "    for m in range(0, nm_img_to_plot):\n",
    "        axes[m, 0].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "        axes[m, 0].set_axis_off()\n",
    "        axes[m, 1].imshow(mask_imgs[im_id], cmap=get_cmap(mask_imgs))\n",
    "        axes[m, 1].set_axis_off()\n",
    "        if not (pred_imgs is None):\n",
    "            axes[m, 2].imshow(pred_imgs[im_id], cmap=get_cmap(pred_imgs))\n",
    "            axes[m, 2].set_axis_off()\n",
    "            axes[m, 3].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "            axes[m, 3].imshow(\n",
    "                mask_to_rgba(\n",
    "                    zero_pad_mask(pred_imgs[im_id], desired_size=org_imgs_size),\n",
    "                    color=color,\n",
    "                ),\n",
    "                cmap=get_cmap(pred_imgs),\n",
    "                alpha=alpha,\n",
    "            )\n",
    "            axes[m, 3].set_axis_off()\n",
    "        else:\n",
    "            axes[m, 2].imshow(org_imgs[im_id], cmap=get_cmap(org_imgs))\n",
    "            axes[m, 2].imshow(\n",
    "                mask_to_rgba(\n",
    "                    zero_pad_mask(mask_imgs[im_id], desired_size=org_imgs_size),\n",
    "                    color=color,\n",
    "                ),\n",
    "                cmap=get_cmap(mask_imgs),\n",
    "                alpha=alpha,\n",
    "            )\n",
    "            axes[m, 2].set_axis_off()\n",
    "        im_id += 1\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "#plot_imgs(org_imgs=trainImgs, mask_imgs=validImgs, nm_img_to_plot=10, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if(path_carregar_pesos == ''):\n",
    "    history = model.fit(trainImgs, validImgs, epochs=epochs,  batch_size=batch_size, validation_split=validation_split)\n",
    "    print('Modelo treinado')\n",
    "else:\n",
    "    model.load_weights(path_carregar_pesos)\n",
    "    print('Pesos carregados')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSaver:\n",
    "    def __init__(self, history, base_output_path):\n",
    "        self.history = history\n",
    "        self.base_output_path = base_output_path\n",
    "        try:\n",
    "            os.mkdir(base_output_path)\n",
    "        except OSError as error:\n",
    "            print(error) \n",
    "        \n",
    "    def saveModel(self, model):\n",
    "        fileName = os.path.join(self.base_output_path,\"result.h5\")\n",
    "        model.save(fileName)\n",
    "        print(\"saved to:\", fileName)\n",
    "        \n",
    "    def plotAndSaveMetrics(self, metric_name, show_val):\n",
    "        plt.plot(self.history.history[str(metric_name)])\n",
    "        if show_val:\n",
    "            plt.plot(self.history.history['val_'+str(metric_name)])\n",
    "        plt.title(\"Acurácia por épocas\")\n",
    "        plt.xlabel(\"épocas\")\n",
    "        plt.legend(['treino','validação'])\n",
    "        output_path =  os.path.join(self.base_output_path,\"acc_por_epocas\")\n",
    "        plt.savefig(output_path)\n",
    "        print(\"saved to:\", output_path)\n",
    "    \n",
    "    def plotAndSaveLoss(self, show_val):\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        if show_val:\n",
    "             plt.plot(self.history.history['val_loss'])\n",
    "        plt.title(\"Perda por épocas\")\n",
    "        plt.xlabel(\"épocas\")\n",
    "        plt.legend(['treino','validação'])\n",
    "        output_path = os.path.join(self.base_output_path,\"loss_por_epocas\")\n",
    "        print(\"saved to:\", output_path)\n",
    "        plt.savefig(output_path)\n",
    "        \n",
    "        \n",
    "    def predictAndSave(self, model, imgs, nomes_imgs, images_to_show):\n",
    "        predict_imgs = model.predict(imgs)\n",
    "        \n",
    "        plot_imgs(org_imgs=imgs, mask_imgs=predict_imgs, nm_img_to_plot=10, figsize=6)\n",
    "             \n",
    "        base_output_result_img = os.path.join(self.base_output_path,\"result-images\")\n",
    "        if(os.path.isdir(base_output_result_img) == False):\n",
    "            try:\n",
    "                os.mkdir(base_output_result_img)\n",
    "            except OSError as error:\n",
    "                print(error) \n",
    "        \n",
    "        for i in range(len(nomes_imgs)):\n",
    "            file_name = nomes_imgs[i].replace(\".jpg\", \".png\")\n",
    "            file_name = file_name.replace(\".jpg\", \".png\")\n",
    "            output_path = os.path.join(base_output_result_img , file_name)\n",
    "            print(\"writing img:\",i,\" to\", output_path)\n",
    "            cv2.imwrite(output_path, predict_imgs[i] * 255.0)\n",
    "\n",
    "    def saveHistory(self):\n",
    "        output_path = os.path.join(self.base_output_path,\"history.csv\")\n",
    "        # convert the history.history dict to a pandas DataFrame:     \n",
    "        hist_df = pd.DataFrame(history.history) \n",
    "        # or save to csv: \n",
    "        #hist_csv_file = 'history.csv'\n",
    "        with open(output_path, mode='w') as f:\n",
    "            hist_df.to_csv(f)\n",
    "        \n",
    "        print(\"saved to:\", output_path)\n",
    "\n",
    "modelSaver = ModelSaver(history, base_output_path)\n",
    "\n",
    "print('ModelSaver criado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSaver.plotAndSaveMetrics(\"acc\", True)\n",
    "#modelSaver.plotAndSaveMetrics(\"mean_io_u\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSaver.plotAndSaveLoss(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSaver.saveModel(model)\n",
    "modelSaver.saveHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliaImgs,avaliaImgsNomes = loadImgs([imgPath + '/Base_A/'], 1)\n",
    "print(len(avaliaImgs))\n",
    "modelSaver.predictAndSave(model, avaliaImgs, avaliaImgsNomes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliaImgs,avaliaImgsNomes = loadImgs(['./Recortes/Base_B/'], 1)\n",
    "print(len(avaliaImgs))\n",
    "modelSaver.predictAndSave(model, avaliaImgs, avaliaImgsNomes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliaImgs,avaliaImgsNomes = loadImgs(['./Recortes/Base_C/'], 1)\n",
    "print(len(avaliaImgs))\n",
    "modelSaver.predictAndSave(model, avaliaImgs, avaliaImgsNomes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliaImgs,avaliaImgsNomes = loadImgs(['./Recortes/Base_D/'], 1)\n",
    "print(len(avaliaImgs))\n",
    "modelSaver.predictAndSave(model, avaliaImgs, avaliaImgsNomes, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
